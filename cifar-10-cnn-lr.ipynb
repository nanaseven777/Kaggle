{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Flatten,Input,Dropout#core layers\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D#convolution layers\nfrom tensorflow.keras.optimizers import Adam, RMSprop\n\nimport math\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, Callback","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-09T18:35:43.704505Z","iopub.execute_input":"2025-02-09T18:35:43.704919Z","iopub.status.idle":"2025-02-09T18:35:43.717315Z","shell.execute_reply.started":"2025-02-09T18:35:43.704894Z","shell.execute_reply":"2025-02-09T18:35:43.715788Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def prepare_data():\n    \"\"\"\n    データの前処理関数\n\n    Returns:\n    x_train(ndarray):訓練データ（50000,32,32,3）\n    x_test(ndarray):テストデータ（10000,32,32,3）\n    y_train(ndarray):正解ラベル（50000,10）\n    y_test(ndarray):正解ラベル（10000,10）\n    \"\"\"\n    (x_train,y_train),(x_test,y_test) = cifar10.load_data()\n    #画像データを正規化\n    x_train, x_test = x_train.astype('float32'),x_test.astype('float32')\n    x_train, x_test = x_train/255.0, x_test/255.0\n    #正解ラベルを10classのOne-Hotに変換\n    y_train, y_test = to_categorical(y_train),to_categorical(y_test)\n\n    return x_train,x_test,y_train,y_test  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:58:32.061687Z","iopub.execute_input":"2025-02-09T17:58:32.062046Z","iopub.status.idle":"2025-02-09T17:58:32.067939Z","shell.execute_reply.started":"2025-02-09T17:58:32.062020Z","shell.execute_reply":"2025-02-09T17:58:32.066757Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#モデル生成\ndef make_convlayer():\n    #畳み込み層1\n    model = Sequential([\n        Input(shape=(32, 32, 3)),\n        Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')\n    ])\n    #プーリング層\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    #畳み込み層2\n    model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n    #プーリング層\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    #畳み込み層3\n    model.add(Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n    #プーリング層\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    # Flatten層\n    model.add(Flatten())\n    # ドロップアウト\n    model.add(Dropout(0.4))\n    #第7層\n    model.add(Dense(512,activation='relu'))\n    #出力層\n    model.add(Dense(10,activation='softmax'))\n\n    # モデルのコンパイル\n    model.compile(\n        optimizer=Adam(lr=0.001),\n        loss=CategoricalCrossentropy(from_logits=False),\n        metrics=['accuracy']\n    )\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T18:32:41.795616Z","iopub.execute_input":"2025-02-09T18:32:41.796212Z","iopub.status.idle":"2025-02-09T18:32:41.804746Z","shell.execute_reply.started":"2025-02-09T18:32:41.796164Z","shell.execute_reply":"2025-02-09T18:32:41.803240Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#ステップ減衰による学習率の推移を記録するコールバック\nclass LRHistory(Callback):\n    def on_train_begin(self,logs={}):\n        self.acc = []\n        self.lr = []\n\n    def on_epoch_end(self, batch, logs={}):\n        self.acc.append(logs.get('acc'))\n        self.lr.append(step_decay(len(self.acc)))\n\ndef step_decay(epoch):\n    \"\"\"\n    ステップ減衰で学習率を降下させる関数\n    Returns:学習率（float）\n    \"\"\"   \n    initial_lrate = 0.001#初期学習率\n    drop = 0.5#減衰率\n    epochs_drop = 10.0#減衰を実行するエポック数\n    lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n    return lrate\n\ndef train(x_train,x_test,y_train,y_test):\n\n    model = make_convlayer()\n    lr_history = LRHistory()\n    lrate = LearningRateScheduler(step_decay)\n    callbacks_list = [lr_history, lrate]\n\n    #データ拡張\n    datagen = ImageDataGenerator(\n        width_shift_range = 0.1,#水平移動\n        height_shift_range=0.1,#垂直移動\n        rotation_range=10,#回転\n        zoom_range=0.1#拡大\n        horizontal_flip=True#左右反転\n    )\n\n    batch_size = 128\n    epochs = 100\n\n    #学習実行\n    history = model.fit(\n        #拡張データをミニバッチ数生成（出力は正規化）\n        datagen.flow(x_train,y_train,batch_size=batch_size),\n        #1回の学習におけるステップ数（画像枚数をミニバッチサイズで割った整数値）\n        steps_per_epoch = x_train.shape[0] // batch_size,\n        epochs = epochs,\n        verbose = 1,\n        validation_data = (x_test,y_test),\n        callbacks = callbacks_list\n    )\n\n    return history, lr_history","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}