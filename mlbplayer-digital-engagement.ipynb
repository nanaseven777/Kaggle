{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":27783,"databundleVersionId":2555459,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#時系列タスクで気を付ける点\n#・説明変数として使って用データは何か？\n#・古いデータは学習に使うべきか？\n#・学習用データセットから検証用データをどう作るか？\n\n#ライブラリのインポート\nimport numpy as np\nimport pandas as pd\nimport pickle\nimport gc\nimport os\nimport datetime as dt\n\nimport matplotlib.pyplot as plt\n\nimport lightgbm as lgb\nfrom lightgbm import early_stopping, log_evaluation\n\nfrom sklearn.metrics import mean_absolute_error\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#表示桁数の指定\npd.options.display.float_format = '{:10.4f}'.format","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T08:59:49.292510Z","iopub.execute_input":"2025-01-25T08:59:49.292884Z","iopub.status.idle":"2025-01-25T08:59:53.450767Z","shell.execute_reply.started":"2025-01-25T08:59:49.292855Z","shell.execute_reply":"2025-01-25T08:59:53.449406Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#ファイルの読み込み、データの確認\ntrain = pd.read_csv(\"/kaggle/input/mlb-player-digital-engagement-forecasting/train_updated.csv\")\nprint(train.shape)\n\n#処理速度を上げるため、データを絞り込む\ntrain = train.loc[train[\"date\"]>=20200401,:].reset_index(drop=True)\nprint(train.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T08:59:53.452164Z","iopub.execute_input":"2025-01-25T08:59:53.452788Z","iopub.status.idle":"2025-01-25T09:01:40.718019Z","shell.execute_reply.started":"2025-01-25T08:59:53.452757Z","shell.execute_reply":"2025-01-25T09:01:40.716399Z"}},"outputs":[{"name":"stdout","text":"(1308, 12)\n(487, 12)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:01:40.719942Z","iopub.execute_input":"2025-01-25T09:01:40.720300Z","iopub.status.idle":"2025-01-25T09:01:40.751090Z","shell.execute_reply.started":"2025-01-25T09:01:40.720269Z","shell.execute_reply":"2025-01-25T09:01:40.749765Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"       date                            nextDayPlayerEngagement games  \\\n0  20200401  [{\"engagementMetricsDate\":\"2020-04-02\",\"player...   NaN   \n1  20200402  [{\"engagementMetricsDate\":\"2020-04-03\",\"player...   NaN   \n2  20200403  [{\"engagementMetricsDate\":\"2020-04-04\",\"player...   NaN   \n3  20200404  [{\"engagementMetricsDate\":\"2020-04-05\",\"player...   NaN   \n4  20200405  [{\"engagementMetricsDate\":\"2020-04-06\",\"player...   NaN   \n\n                                             rosters playerBoxScores  \\\n0  [{\"playerId\":430935,\"gameDate\":\"2020-04-01\",\"t...             NaN   \n1  [{\"playerId\":405395,\"gameDate\":\"2020-04-02\",\"t...             NaN   \n2  [{\"playerId\":425844,\"gameDate\":\"2020-04-03\",\"t...             NaN   \n3  [{\"playerId\":405395,\"gameDate\":\"2020-04-04\",\"t...             NaN   \n4  [{\"playerId\":408234,\"gameDate\":\"2020-04-05\",\"t...             NaN   \n\n  teamBoxScores transactions standings awards events  \\\n0           NaN          NaN       NaN    NaN    NaN   \n1           NaN          NaN       NaN    NaN    NaN   \n2           NaN          NaN       NaN    NaN    NaN   \n3           NaN          NaN       NaN    NaN    NaN   \n4           NaN          NaN       NaN    NaN    NaN   \n\n                              playerTwitterFollowers  \\\n0  [{\"date\":\"2020-04-01\",\"playerId\":545361,\"playe...   \n1                                                NaN   \n2                                                NaN   \n3                                                NaN   \n4                                                NaN   \n\n                                teamTwitterFollowers  \n0  [{\"date\":\"2020-04-01\",\"teamId\":147,\"teamName\":...  \n1                                                NaN  \n2                                                NaN  \n3                                                NaN  \n4                                                NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>nextDayPlayerEngagement</th>\n      <th>games</th>\n      <th>rosters</th>\n      <th>playerBoxScores</th>\n      <th>teamBoxScores</th>\n      <th>transactions</th>\n      <th>standings</th>\n      <th>awards</th>\n      <th>events</th>\n      <th>playerTwitterFollowers</th>\n      <th>teamTwitterFollowers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20200401</td>\n      <td>[{\"engagementMetricsDate\":\"2020-04-02\",\"player...</td>\n      <td>NaN</td>\n      <td>[{\"playerId\":430935,\"gameDate\":\"2020-04-01\",\"t...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[{\"date\":\"2020-04-01\",\"playerId\":545361,\"playe...</td>\n      <td>[{\"date\":\"2020-04-01\",\"teamId\":147,\"teamName\":...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20200402</td>\n      <td>[{\"engagementMetricsDate\":\"2020-04-03\",\"player...</td>\n      <td>NaN</td>\n      <td>[{\"playerId\":405395,\"gameDate\":\"2020-04-02\",\"t...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20200403</td>\n      <td>[{\"engagementMetricsDate\":\"2020-04-04\",\"player...</td>\n      <td>NaN</td>\n      <td>[{\"playerId\":425844,\"gameDate\":\"2020-04-03\",\"t...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20200404</td>\n      <td>[{\"engagementMetricsDate\":\"2020-04-05\",\"player...</td>\n      <td>NaN</td>\n      <td>[{\"playerId\":405395,\"gameDate\":\"2020-04-04\",\"t...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20200405</td>\n      <td>[{\"engagementMetricsDate\":\"2020-04-06\",\"player...</td>\n      <td>NaN</td>\n      <td>[{\"playerId\":408234,\"gameDate\":\"2020-04-05\",\"t...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"#json形式の列を表形式に直す関数\ndef unpack_json(json_str):\n    return np.nan if pd.isna(json_str) else pd.read_json(json_str)\n\ndef extract_data(input_df, col=\"events\", show=False):\n    output_df = pd.DataFrame()\n    for i in np.arange(len(input_df)):\n        if show: print(\"\\r{}/{}\".format(i+1, len(input_df)), end=\"\")\n        try:\n            output_df = pd.concat([\n                output_df,\n                unpack_json(input_df[col].iloc[i])\n            ],axis=0, ignore_index=True)\n        except:\n            pass\n    if show:print(\"\")\n    if show:print(output_df.shape)\n    if show:display(output_df.head())\n    return output_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:01:40.753063Z","iopub.execute_input":"2025-01-25T09:01:40.753480Z","iopub.status.idle":"2025-01-25T09:01:40.761853Z","shell.execute_reply.started":"2025-01-25T09:01:40.753448Z","shell.execute_reply":"2025-01-25T09:01:40.760364Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#engagementを取り出して表形式に変換\ndf_engagement = extract_data(train, col=\"nextDayPlayerEngagement\",show=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:01:40.763245Z","iopub.execute_input":"2025-01-25T09:01:40.763661Z","iopub.status.idle":"2025-01-25T09:01:58.956272Z","shell.execute_reply.started":"2025-01-25T09:01:40.763615Z","shell.execute_reply":"2025-01-25T09:01:58.954745Z"}},"outputs":[{"name":"stdout","text":"487/487\n(1003707, 6)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  engagementMetricsDate  playerId    target1    target2    target3    target4\n0            2020-04-02    425794     5.1249     9.4340     0.1179     6.1947\n1            2020-04-02    571704     0.0389     8.1761     0.0105     2.1304\n2            2020-04-02    506702     0.0106     5.0314     0.0082     0.8850\n3            2020-04-02    607231     0.0247     2.8302     0.0222     0.5900\n4            2020-04-02    543193     0.0071     1.1006     0.0012     0.1967","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>engagementMetricsDate</th>\n      <th>playerId</th>\n      <th>target1</th>\n      <th>target2</th>\n      <th>target3</th>\n      <th>target4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-04-02</td>\n      <td>425794</td>\n      <td>5.1249</td>\n      <td>9.4340</td>\n      <td>0.1179</td>\n      <td>6.1947</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-04-02</td>\n      <td>571704</td>\n      <td>0.0389</td>\n      <td>8.1761</td>\n      <td>0.0105</td>\n      <td>2.1304</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-04-02</td>\n      <td>506702</td>\n      <td>0.0106</td>\n      <td>5.0314</td>\n      <td>0.0082</td>\n      <td>0.8850</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-04-02</td>\n      <td>607231</td>\n      <td>0.0247</td>\n      <td>2.8302</td>\n      <td>0.0222</td>\n      <td>0.5900</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-04-02</td>\n      <td>543193</td>\n      <td>0.0071</td>\n      <td>1.1006</td>\n      <td>0.0012</td>\n      <td>0.1967</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"#df_engagementの前処理\n#結合キーの作成\ndf_engagement[\"date_playerId\"] = df_engagement[\"engagementMetricsDate\"].str.replace(\n    \"-\",\"\") + \"_\" + df_engagement[\"playerId\"].astype(str)\ndf_engagement.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:01:58.957925Z","iopub.execute_input":"2025-01-25T09:01:58.958433Z","iopub.status.idle":"2025-01-25T09:02:02.053119Z","shell.execute_reply.started":"2025-01-25T09:01:58.958390Z","shell.execute_reply":"2025-01-25T09:02:02.051295Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"  engagementMetricsDate  playerId    target1    target2    target3    target4  \\\n0            2020-04-02    425794     5.1249     9.4340     0.1179     6.1947   \n1            2020-04-02    571704     0.0389     8.1761     0.0105     2.1304   \n2            2020-04-02    506702     0.0106     5.0314     0.0082     0.8850   \n3            2020-04-02    607231     0.0247     2.8302     0.0222     0.5900   \n4            2020-04-02    543193     0.0071     1.1006     0.0012     0.1967   \n\n     date_playerId  \n0  20200402_425794  \n1  20200402_571704  \n2  20200402_506702  \n3  20200402_607231  \n4  20200402_543193  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>engagementMetricsDate</th>\n      <th>playerId</th>\n      <th>target1</th>\n      <th>target2</th>\n      <th>target3</th>\n      <th>target4</th>\n      <th>date_playerId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-04-02</td>\n      <td>425794</td>\n      <td>5.1249</td>\n      <td>9.4340</td>\n      <td>0.1179</td>\n      <td>6.1947</td>\n      <td>20200402_425794</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-04-02</td>\n      <td>571704</td>\n      <td>0.0389</td>\n      <td>8.1761</td>\n      <td>0.0105</td>\n      <td>2.1304</td>\n      <td>20200402_571704</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-04-02</td>\n      <td>506702</td>\n      <td>0.0106</td>\n      <td>5.0314</td>\n      <td>0.0082</td>\n      <td>0.8850</td>\n      <td>20200402_506702</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-04-02</td>\n      <td>607231</td>\n      <td>0.0247</td>\n      <td>2.8302</td>\n      <td>0.0222</td>\n      <td>0.5900</td>\n      <td>20200402_607231</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-04-02</td>\n      <td>543193</td>\n      <td>0.0071</td>\n      <td>1.1006</td>\n      <td>0.0012</td>\n      <td>0.1967</td>\n      <td>20200402_543193</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"#日付から特徴量を作成\n#推論実施日カラム（推論実施日=推論対象日の前日）\ndf_engagement[\"date\"] = pd.to_datetime(df_engagement[\"engagementMetricsDate\"],\n                                      format=\"%Y-%m-%d\") + dt.timedelta(days=-1)\n#推論実施日の「曜日」と「年月」特徴量\ndf_engagement[\"dayofweek\"] = df_engagement[\"date\"].dt.dayofweek\ndf_engagement[\"yearmonth\"] = df_engagement[\"date\"].astype(str).apply(lambda x: x[:7])\ndf_engagement.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:02.054991Z","iopub.execute_input":"2025-01-25T09:02:02.055473Z","iopub.status.idle":"2025-01-25T09:02:03.697275Z","shell.execute_reply.started":"2025-01-25T09:02:02.055429Z","shell.execute_reply":"2025-01-25T09:02:03.696201Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"  engagementMetricsDate  playerId    target1    target2    target3    target4  \\\n0            2020-04-02    425794     5.1249     9.4340     0.1179     6.1947   \n1            2020-04-02    571704     0.0389     8.1761     0.0105     2.1304   \n2            2020-04-02    506702     0.0106     5.0314     0.0082     0.8850   \n3            2020-04-02    607231     0.0247     2.8302     0.0222     0.5900   \n4            2020-04-02    543193     0.0071     1.1006     0.0012     0.1967   \n\n     date_playerId       date  dayofweek yearmonth  \n0  20200402_425794 2020-04-01          2   2020-04  \n1  20200402_571704 2020-04-01          2   2020-04  \n2  20200402_506702 2020-04-01          2   2020-04  \n3  20200402_607231 2020-04-01          2   2020-04  \n4  20200402_543193 2020-04-01          2   2020-04  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>engagementMetricsDate</th>\n      <th>playerId</th>\n      <th>target1</th>\n      <th>target2</th>\n      <th>target3</th>\n      <th>target4</th>\n      <th>date_playerId</th>\n      <th>date</th>\n      <th>dayofweek</th>\n      <th>yearmonth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-04-02</td>\n      <td>425794</td>\n      <td>5.1249</td>\n      <td>9.4340</td>\n      <td>0.1179</td>\n      <td>6.1947</td>\n      <td>20200402_425794</td>\n      <td>2020-04-01</td>\n      <td>2</td>\n      <td>2020-04</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-04-02</td>\n      <td>571704</td>\n      <td>0.0389</td>\n      <td>8.1761</td>\n      <td>0.0105</td>\n      <td>2.1304</td>\n      <td>20200402_571704</td>\n      <td>2020-04-01</td>\n      <td>2</td>\n      <td>2020-04</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-04-02</td>\n      <td>506702</td>\n      <td>0.0106</td>\n      <td>5.0314</td>\n      <td>0.0082</td>\n      <td>0.8850</td>\n      <td>20200402_506702</td>\n      <td>2020-04-01</td>\n      <td>2</td>\n      <td>2020-04</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-04-02</td>\n      <td>607231</td>\n      <td>0.0247</td>\n      <td>2.8302</td>\n      <td>0.0222</td>\n      <td>0.5900</td>\n      <td>20200402_607231</td>\n      <td>2020-04-01</td>\n      <td>2</td>\n      <td>2020-04</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-04-02</td>\n      <td>543193</td>\n      <td>0.0071</td>\n      <td>1.1006</td>\n      <td>0.0012</td>\n      <td>0.1967</td>\n      <td>20200402_543193</td>\n      <td>2020-04-01</td>\n      <td>2</td>\n      <td>2020-04</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"#players.csvの読み込み\ndf_players = pd.read_csv(\"/kaggle/input/mlb-player-digital-engagement-forecasting/players.csv\")\nprint(df_players.shape)\nprint(df_players[\"playerId\"].agg(\"nunique\"))\ndf_players.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:03.700335Z","iopub.execute_input":"2025-01-25T09:02:03.700673Z","iopub.status.idle":"2025-01-25T09:02:03.745409Z","shell.execute_reply.started":"2025-01-25T09:02:03.700643Z","shell.execute_reply":"2025-01-25T09:02:03.744207Z"}},"outputs":[{"name":"stdout","text":"(2061, 12)\n2061\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   playerId          playerName         DOB mlbDebutDate            birthCity  \\\n0    665482  Gilberto Celestino  1999-02-13   2021-06-02        Santo Domingo   \n1    593590       Webster Rivas  1990-08-08   2021-05-28                Nagua   \n2    661269  Vladimir Gutierrez  1995-09-18   2021-05-28               Havana   \n3    669212          Eli Morgan  1996-05-13   2021-05-28  Rancho Palos Verdes   \n4    666201         Alek Manoah  1998-01-09   2021-05-27            Homestead   \n\n  birthStateProvince        birthCountry  heightInches  weight  \\\n0                NaN  Dominican Republic            72     170   \n1                NaN  Dominican Republic            73     219   \n2                NaN                Cuba            73     190   \n3                 CA                 USA            70     190   \n4                 FL                 USA            78     260   \n\n  primaryPositionCode primaryPositionName playerForTestSetAndFuturePreds  \n0                   8          Outfielder                          False  \n1                   3          First Base                           True  \n2                   1             Pitcher                           True  \n3                   1             Pitcher                           True  \n4                   1             Pitcher                           True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>playerId</th>\n      <th>playerName</th>\n      <th>DOB</th>\n      <th>mlbDebutDate</th>\n      <th>birthCity</th>\n      <th>birthStateProvince</th>\n      <th>birthCountry</th>\n      <th>heightInches</th>\n      <th>weight</th>\n      <th>primaryPositionCode</th>\n      <th>primaryPositionName</th>\n      <th>playerForTestSetAndFuturePreds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>665482</td>\n      <td>Gilberto Celestino</td>\n      <td>1999-02-13</td>\n      <td>2021-06-02</td>\n      <td>Santo Domingo</td>\n      <td>NaN</td>\n      <td>Dominican Republic</td>\n      <td>72</td>\n      <td>170</td>\n      <td>8</td>\n      <td>Outfielder</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>593590</td>\n      <td>Webster Rivas</td>\n      <td>1990-08-08</td>\n      <td>2021-05-28</td>\n      <td>Nagua</td>\n      <td>NaN</td>\n      <td>Dominican Republic</td>\n      <td>73</td>\n      <td>219</td>\n      <td>3</td>\n      <td>First Base</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>661269</td>\n      <td>Vladimir Gutierrez</td>\n      <td>1995-09-18</td>\n      <td>2021-05-28</td>\n      <td>Havana</td>\n      <td>NaN</td>\n      <td>Cuba</td>\n      <td>73</td>\n      <td>190</td>\n      <td>1</td>\n      <td>Pitcher</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>669212</td>\n      <td>Eli Morgan</td>\n      <td>1996-05-13</td>\n      <td>2021-05-28</td>\n      <td>Rancho Palos Verdes</td>\n      <td>CA</td>\n      <td>USA</td>\n      <td>70</td>\n      <td>190</td>\n      <td>1</td>\n      <td>Pitcher</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>666201</td>\n      <td>Alek Manoah</td>\n      <td>1998-01-09</td>\n      <td>2021-05-27</td>\n      <td>Homestead</td>\n      <td>FL</td>\n      <td>USA</td>\n      <td>78</td>\n      <td>260</td>\n      <td>1</td>\n      <td>Pitcher</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"#テストデータの評価対象者の確認\ndf_players[\"playerForTestSetAndFuturePreds\"] = np.where(df_players[\"playerForTestSetAndFuturePreds\"\n                                                        ]==True,1,0)\nprint(df_players[\"playerForTestSetAndFuturePreds\"].sum())\nprint(df_players[\"playerForTestSetAndFuturePreds\"].mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:03.748383Z","iopub.execute_input":"2025-01-25T09:02:03.748851Z","iopub.status.idle":"2025-01-25T09:02:03.761722Z","shell.execute_reply.started":"2025-01-25T09:02:03.748811Z","shell.execute_reply":"2025-01-25T09:02:03.759896Z"}},"outputs":[{"name":"stdout","text":"1187\n0.5759340126152354\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#データセット作成\n\n#テーブル結合\ndf_train = pd.merge(df_engagement,df_players,on=[\"playerId\"],how=\"left\")\nprint(df_train.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:03.763195Z","iopub.execute_input":"2025-01-25T09:02:03.763836Z","iopub.status.idle":"2025-01-25T09:02:04.219357Z","shell.execute_reply.started":"2025-01-25T09:02:03.763787Z","shell.execute_reply":"2025-01-25T09:02:04.218097Z"}},"outputs":[{"name":"stdout","text":"(1003707, 21)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"x_train = df_train[[\n    \"playerId\",\"dayofweek\",\"birthCity\",\"birthStateProvince\",\"birthCountry\",\"heightInches\",\n    \"weight\",\"primaryPositionCode\",\"primaryPositionName\",\"playerForTestSetAndFuturePreds\"]]\ny_train = df_train[[\"target1\",\"target2\",\"target3\",\"target4\"]]\nid_train = df_train[[\"engagementMetricsDate\",\"playerId\",\"date_playerId\",\"date\",\"yearmonth\",\"playerForTestSetAndFuturePreds\"]]\nprint(x_train.shape,y_train.shape,id_train.shape)\nx_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:04.220495Z","iopub.execute_input":"2025-01-25T09:02:04.220822Z","iopub.status.idle":"2025-01-25T09:02:04.340651Z","shell.execute_reply.started":"2025-01-25T09:02:04.220792Z","shell.execute_reply":"2025-01-25T09:02:04.339185Z"}},"outputs":[{"name":"stdout","text":"(1003707, 10) (1003707, 4) (1003707, 6)\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   playerId  dayofweek    birthCity birthStateProvince birthCountry  \\\n0    425794          2    Brunswick                 GA          USA   \n1    571704          2  Albuquerque                 NM          USA   \n2    506702          2    Maracaibo                NaN    Venezuela   \n3    607231          2     Savannah                 GA          USA   \n4    543193          2     Columbia                 CA          USA   \n\n   heightInches  weight primaryPositionCode primaryPositionName  \\\n0            79     230                   1             Pitcher   \n1            75     210                   1             Pitcher   \n2            70     235                   2             Catcher   \n3            76     200                   1             Pitcher   \n4            76     215                   1             Pitcher   \n\n   playerForTestSetAndFuturePreds  \n0                               1  \n1                               0  \n2                               1  \n3                               1  \n4                               0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>playerId</th>\n      <th>dayofweek</th>\n      <th>birthCity</th>\n      <th>birthStateProvince</th>\n      <th>birthCountry</th>\n      <th>heightInches</th>\n      <th>weight</th>\n      <th>primaryPositionCode</th>\n      <th>primaryPositionName</th>\n      <th>playerForTestSetAndFuturePreds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>425794</td>\n      <td>2</td>\n      <td>Brunswick</td>\n      <td>GA</td>\n      <td>USA</td>\n      <td>79</td>\n      <td>230</td>\n      <td>1</td>\n      <td>Pitcher</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>571704</td>\n      <td>2</td>\n      <td>Albuquerque</td>\n      <td>NM</td>\n      <td>USA</td>\n      <td>75</td>\n      <td>210</td>\n      <td>1</td>\n      <td>Pitcher</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>506702</td>\n      <td>2</td>\n      <td>Maracaibo</td>\n      <td>NaN</td>\n      <td>Venezuela</td>\n      <td>70</td>\n      <td>235</td>\n      <td>2</td>\n      <td>Catcher</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>607231</td>\n      <td>2</td>\n      <td>Savannah</td>\n      <td>GA</td>\n      <td>USA</td>\n      <td>76</td>\n      <td>200</td>\n      <td>1</td>\n      <td>Pitcher</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>543193</td>\n      <td>2</td>\n      <td>Columbia</td>\n      <td>CA</td>\n      <td>USA</td>\n      <td>76</td>\n      <td>215</td>\n      <td>1</td>\n      <td>Pitcher</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"#category型に変換\nfor col in [\"playerId\",\"dayofweek\",\"birthCity\",\"birthStateProvince\",\"birthCountry\",\n           \"primaryPositionCode\",\"primaryPositionName\"]:\n    x_train[col] = x_train[col].astype(\"category\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:04.341896Z","iopub.execute_input":"2025-01-25T09:02:04.342300Z","iopub.status.idle":"2025-01-25T09:02:04.688513Z","shell.execute_reply.started":"2025-01-25T09:02:04.342252Z","shell.execute_reply":"2025-01-25T09:02:04.687309Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"#バリデーション設計\n\n#学習データと検証データの期間設定\nlist_cv_month = [\n    [[\"2020-05\",\"2020-06\",\"2020-07\",\"2020-08\",\"2020-09\",\"2020-10\",\"2020-11\",\"2020-12\",\"2021-01\",\n     \"2021-02\",\"2021-03\",\"2021-04\"],[\"2021-05\"]],\n    [[\"2020-06\",\"2020-07\",\"2020-08\",\"2020-09\",\"2020-10\",\"2020-11\",\"2020-12\",\"2021-01\",\n     \"2021-02\",\"2021-03\",\"2021-04\",\"2021-05\"],[\"2021-06\"]],\n    [[\"2020-07\",\"2020-08\",\"2020-09\",\"2020-10\",\"2020-11\",\"2020-12\",\"2021-01\",\n     \"2021-02\",\"2021-03\",\"2021-04\",\"2021-05\",\"2021-06\"],[\"2021-07\"]],\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:04.689706Z","iopub.execute_input":"2025-01-25T09:02:04.690110Z","iopub.status.idle":"2025-01-25T09:02:04.696284Z","shell.execute_reply.started":"2025-01-25T09:02:04.690070Z","shell.execute_reply":"2025-01-25T09:02:04.695266Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#学習データ、検証データのindexリストを作成\ncv = []\nfor month_tr,month_va in list_cv_month:\n    cv.append([\n        id_train.index[id_train[\"yearmonth\"].isin(month_tr)],\n        id_train.index[id_train[\"yearmonth\"].isin(month_va) &\n        (id_train[\"playerForTestSetAndFuturePreds\"]==1)],\n    ])\n#fold0のindexリスト\ncv[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:04.697657Z","iopub.execute_input":"2025-01-25T09:02:04.697960Z","iopub.status.idle":"2025-01-25T09:02:05.027550Z","shell.execute_reply.started":"2025-01-25T09:02:04.697935Z","shell.execute_reply":"2025-01-25T09:02:05.026614Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[Index([ 61830,  61831,  61832,  61833,  61834,  61835,  61836,  61837,  61838,\n         61839,\n        ...\n        814085, 814086, 814087, 814088, 814089, 814090, 814091, 814092, 814093,\n        814094],\n       dtype='int64', length=752265),\n Index([814095, 814096, 814100, 814101, 814102, 814104, 814105, 814106, 814107,\n        814109,\n        ...\n        877931, 877934, 877950, 877951, 877957, 877958, 877969, 877972, 877974,\n        877975],\n       dtype='int64', length=36797)]"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"#モデル学習\n\n#目的変数「target1」、fold「fold1」の場合\ntarget = \"target1\"\nnfold = 0\n\n#train,validのindex取得\nidx_tr,idx_va = cv[nfold][0],cv[nfold][1]\n\n#学習データと検証データに分離\nx_tr,y_tr,id_tr = x_train.loc[idx_tr,:],y_train.loc[idx_tr,target],id_train.loc[idx_tr,:]\nx_va,y_va,id_va = x_train.loc[idx_va,:],y_train.loc[idx_va,target],id_train.loc[idx_va,:]\nprint(x_tr.shape,y_tr.shape,id_tr.shape)\nprint(x_va.shape,y_va.shape,id_va.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:05.028626Z","iopub.execute_input":"2025-01-25T09:02:05.028899Z","iopub.status.idle":"2025-01-25T09:02:05.244185Z","shell.execute_reply.started":"2025-01-25T09:02:05.028876Z","shell.execute_reply":"2025-01-25T09:02:05.242839Z"}},"outputs":[{"name":"stdout","text":"(752265, 10) (752265,) (752265, 6)\n(36797, 10) (36797,) (36797, 6)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"#ハイパーパラメータの設定\nparams = {\n    'boosting_type':'gbdt',\n    'objective':'regression_l1',\n    'metric':'mean_absolute_error',\n    'learning_rate':0.05,\n    'num_leaves':32,\n    'subsample':0.7,\n    'subsample_freq':1,\n    'feature_fraction':0.8,\n    'min_data_in_leaf':50,\n    'min_sum_hessian_in_leaf':50,\n    'n_estimators':1000,\n    \"random_state\":123,\n    \"importance_type\":\"gain\",\n}\n\n#モデルの学習\nmodel = lgb.LGBMRegressor(**params)\nverbose_eval = 100\nmodel.fit(x_tr,\n         y_tr,\n         eval_set=[(x_tr,y_tr),(x_va,y_va)],\n         callbacks=[\n        early_stopping(stopping_rounds=50),  # 早期停止のコールバック\n        log_evaluation(verbose_eval)]          # ログ表示のコールバック\n         )\n\n#モデルの保存\nwith open(\"model_lgb_target1_fold0.h5\",\"wb\") as f:#h5は深層学習用拡張子\n    pickle.dump(model,f,protocol=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:05.245299Z","iopub.execute_input":"2025-01-25T09:02:05.245656Z","iopub.status.idle":"2025-01-25T09:02:32.156120Z","shell.execute_reply.started":"2025-01-25T09:02:05.245625Z","shell.execute_reply":"2025-01-25T09:02:32.154448Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018969 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3300\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 10\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.001289\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 0.50831\tvalid_1's l1: 1.29786\n[200]\ttraining's l1: 0.508183\tvalid_1's l1: 1.29768\n[300]\ttraining's l1: 0.508143\tvalid_1's l1: 1.29767\nEarly stopping, best iteration is:\n[258]\ttraining's l1: 0.508161\tvalid_1's l1: 1.29766\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"#モデル評価\n#検証データの推論値取得\ny_va_pred = model.predict(x_va)\n\n#全target/foldの推論値を格納する変数の作成\ndf_valid_pred = pd.DataFrame()\n\n#推論値を格納\ntmp_pred = pd.concat([\n    id_va,\n    pd.DataFrame({\"target\":target,\"nfold\":0,\"true\":y_va,\"pred\":y_va_pred}),\n],axis=1)\ndf_valid_pred = pd.concat([df_valid_pred, tmp_pred], axis=0, ignore_index=True)\n\n#全target/foldの評価値を入れる変数の作成\nmetrics = []\n\n#評価値の算出\nmetrics_va = mean_absolute_error(y_va,y_va_pred)\n#評価値を格納\nmetrics.append([target,nfold,metrics_va])\nmetrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:32.157494Z","iopub.execute_input":"2025-01-25T09:02:32.157940Z","iopub.status.idle":"2025-01-25T09:02:32.934715Z","shell.execute_reply.started":"2025-01-25T09:02:32.157910Z","shell.execute_reply":"2025-01-25T09:02:32.930419Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[['target1', 0, 1.2976578174338422]]"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"#説明変数の重要度取得\ntmp_imp = pd.DataFrame({\"col\":x_tr.columns,\"imp\":model.feature_importances_,\n                       \"target\":\"target1\",\"nfold\":nfold})\n#確認\ndisplay(tmp_imp.sort_values(\"imp\",ascending=False))\n#全target/foldの重要度を格納するデータフレームの作成\ndf_imp = pd.DataFrame()\n#imp_foldをdf_impに結合\ndf_imp = pd.concat([df_imp,tmp_imp],axis=0,ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:32.937040Z","iopub.execute_input":"2025-01-25T09:02:32.937766Z","iopub.status.idle":"2025-01-25T09:02:32.970315Z","shell.execute_reply.started":"2025-01-25T09:02:32.937716Z","shell.execute_reply":"2025-01-25T09:02:32.968653Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                              col           imp   target  nfold\n0                        playerId 13595482.8115  target1      0\n9  playerForTestSetAndFuturePreds  2314285.0327  target1      0\n2                       birthCity  2249420.1773  target1      0\n7             primaryPositionCode   523633.5634  target1      0\n8             primaryPositionName    91211.0063  target1      0\n1                       dayofweek    89016.5762  target1      0\n3              birthStateProvince    35673.0473  target1      0\n6                          weight    30337.5720  target1      0\n5                    heightInches    20493.2084  target1      0\n4                    birthCountry     4882.0330  target1      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col</th>\n      <th>imp</th>\n      <th>target</th>\n      <th>nfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>playerId</td>\n      <td>13595482.8115</td>\n      <td>target1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>playerForTestSetAndFuturePreds</td>\n      <td>2314285.0327</td>\n      <td>target1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>birthCity</td>\n      <td>2249420.1773</td>\n      <td>target1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>primaryPositionCode</td>\n      <td>523633.5634</td>\n      <td>target1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>primaryPositionName</td>\n      <td>91211.0063</td>\n      <td>target1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dayofweek</td>\n      <td>89016.5762</td>\n      <td>target1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>birthStateProvince</td>\n      <td>35673.0473</td>\n      <td>target1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>weight</td>\n      <td>30337.5720</td>\n      <td>target1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>heightInches</td>\n      <td>20493.2084</td>\n      <td>target1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>birthCountry</td>\n      <td>4882.0330</td>\n      <td>target1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"#モデルの評価\n#リスト型をデータフレームに変換\ndf_metrics = pd.DataFrame(metrics,columns=[\"target\",\"nfold\",\"mae\"])\ndisplay(df_metrics.head())\n\n#評価値\nprint(\"MCMAE: {:.4f}\".format(df_metrics[\"mae\"].mean()))\n\ndisplay(pd.pivot_table(df_metrics,index=\"nfold\",columns=\"target\",values=\"mae\",\n                      aggfunc=np.mean,margins=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:32.971730Z","iopub.execute_input":"2025-01-25T09:02:32.972817Z","iopub.status.idle":"2025-01-25T09:02:33.073351Z","shell.execute_reply.started":"2025-01-25T09:02:32.972592Z","shell.execute_reply":"2025-01-25T09:02:33.071041Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"    target  nfold        mae\n0  target1      0     1.2977","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>nfold</th>\n      <th>mae</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>target1</td>\n      <td>0</td>\n      <td>1.2977</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"MCMAE: 1.2977\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"target    target1        All\nnfold                       \n0          1.2977     1.2977\nAll        1.2977     1.2977","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>target</th>\n      <th>target1</th>\n      <th>All</th>\n    </tr>\n    <tr>\n      <th>nfold</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.2977</td>\n      <td>1.2977</td>\n    </tr>\n    <tr>\n      <th>All</th>\n      <td>1.2977</td>\n      <td>1.2977</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"#検証データの推論値の形式変換\ndf_valid_pred_all = pd.pivot_table(df_valid_pred,index=\n                                   [\"engagementMetricsDate\",\"playerId\",\"date_playerId\",\n                                    \"date\",\"yearmonth\",\"playerForTestSetAndFuturePreds\"],\n                                   columns=[\"target\",\"nfold\"],values=[\"true\",\"pred\"],aggfunc=np.sum)\ndf_valid_pred_all.columns = [\"{}_fold{}_{}\".format(j,k,i)for i,j,k in df_valid_pred_all.columns]\ndf_valid_pred_all = df_valid_pred_all.reset_index(drop=False)\ndf_valid_pred_all.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:33.076544Z","iopub.execute_input":"2025-01-25T09:02:33.077317Z","iopub.status.idle":"2025-01-25T09:02:33.217782Z","shell.execute_reply.started":"2025-01-25T09:02:33.077267Z","shell.execute_reply":"2025-01-25T09:02:33.215826Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"  engagementMetricsDate  playerId    date_playerId       date yearmonth  \\\n0            2021-05-02    405395  20210502_405395 2021-05-01   2021-05   \n1            2021-05-02    408234  20210502_408234 2021-05-01   2021-05   \n2            2021-05-02    424144  20210502_424144 2021-05-01   2021-05   \n3            2021-05-02    425772  20210502_425772 2021-05-01   2021-05   \n4            2021-05-02    425784  20210502_425784 2021-05-01   2021-05   \n\n   playerForTestSetAndFuturePreds  target1_fold0_pred  target1_fold0_true  \n0                               1              0.6049              0.1518  \n1                               1              0.3317              0.2365  \n2                               1              0.0020              0.0016  \n3                               1              0.0065              0.0035  \n4                               1              0.0008              0.0001  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>engagementMetricsDate</th>\n      <th>playerId</th>\n      <th>date_playerId</th>\n      <th>date</th>\n      <th>yearmonth</th>\n      <th>playerForTestSetAndFuturePreds</th>\n      <th>target1_fold0_pred</th>\n      <th>target1_fold0_true</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-05-02</td>\n      <td>405395</td>\n      <td>20210502_405395</td>\n      <td>2021-05-01</td>\n      <td>2021-05</td>\n      <td>1</td>\n      <td>0.6049</td>\n      <td>0.1518</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-05-02</td>\n      <td>408234</td>\n      <td>20210502_408234</td>\n      <td>2021-05-01</td>\n      <td>2021-05</td>\n      <td>1</td>\n      <td>0.3317</td>\n      <td>0.2365</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-05-02</td>\n      <td>424144</td>\n      <td>20210502_424144</td>\n      <td>2021-05-01</td>\n      <td>2021-05</td>\n      <td>1</td>\n      <td>0.0020</td>\n      <td>0.0016</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-05-02</td>\n      <td>425772</td>\n      <td>20210502_425772</td>\n      <td>2021-05-01</td>\n      <td>2021-05</td>\n      <td>1</td>\n      <td>0.0065</td>\n      <td>0.0035</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-05-02</td>\n      <td>425784</td>\n      <td>20210502_425784</td>\n      <td>2021-05-01</td>\n      <td>2021-05</td>\n      <td>1</td>\n      <td>0.0008</td>\n      <td>0.0001</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"#説明変数の重要度取得\ndf_imp.groupby([\"col\"])[\"imp\"].agg([\"mean\",\"std\"]).sort_values(\"mean\",ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:33.219668Z","iopub.execute_input":"2025-01-25T09:02:33.220541Z","iopub.status.idle":"2025-01-25T09:02:33.241900Z","shell.execute_reply.started":"2025-01-25T09:02:33.220376Z","shell.execute_reply":"2025-01-25T09:02:33.239837Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                        mean  std\ncol                                              \nplayerId                       13595482.8115  NaN\nplayerForTestSetAndFuturePreds  2314285.0327  NaN\nbirthCity                       2249420.1773  NaN\nprimaryPositionCode              523633.5634  NaN\nprimaryPositionName               91211.0063  NaN\ndayofweek                         89016.5762  NaN\nbirthStateProvince                35673.0473  NaN\nweight                            30337.5720  NaN\nheightInches                      20493.2084  NaN\nbirthCountry                       4882.0330  NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n    <tr>\n      <th>col</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>playerId</th>\n      <td>13595482.8115</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>playerForTestSetAndFuturePreds</th>\n      <td>2314285.0327</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>birthCity</th>\n      <td>2249420.1773</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>primaryPositionCode</th>\n      <td>523633.5634</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>primaryPositionName</th>\n      <td>91211.0063</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>dayofweek</th>\n      <td>89016.5762</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>birthStateProvince</th>\n      <td>35673.0473</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>weight</th>\n      <td>30337.5720</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>heightInches</th>\n      <td>20493.2084</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>birthCountry</th>\n      <td>4882.0330</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"#学習用関数の作成\ndef train_lgb(input_x,\n              input_y,\n              input_id,\n              params,\n              list_nfold=[0,1,2], \n              mode_train=\"train\",\n             ):\n    #推論値を格納する変数の作成\n    df_valid_pred = pd.DataFrame()\n    #評価値を入れる変数の作成\n    metrics = []\n    #重要度を格納するデータフレームの作成\n    df_imp = pd.DataFrame()\n\n    #validation\n    cv = []\n    for month_tr,month_va in list_cv_month:\n        cv.append([\n            input_id.index[input_id[\"yearmonth\"].isin(month_tr)],\n            input_id.index[input_id[\"yearmonth\"].isin(month_va) &\n            (input_id[\"playerForTestSetAndFuturePreds\"]==1)],\n        ])\n\n    #モデル学習(target/foldごとに学習)\n    for nfold in list_nfold:\n        for i,target in enumerate([\"target1\",\"target2\",\"target3\",\"target4\"]):\n            print(\"-\"*20,target,\",fold:\", nfold,\"-\"*20)\n            #trainとvalidに分離\n            idx_tr,idx_va = cv[nfold][0],cv[nfold][1]\n            x_tr,y_tr,id_tr = x_train.loc[idx_tr,:],y_train.loc[idx_tr,target],id_train.loc[idx_tr,:]\n            x_va,y_va,id_va = x_train.loc[idx_va,:],y_train.loc[idx_va,target],id_train.loc[idx_va,:]\n            print(x_tr.shape,y_tr.shape,id_tr.shape)\n            print(x_va.shape,y_va.shape,id_va.shape)\n\n            #保存するモデルのファイル名\n            filepath = \"model_lgb_{}_fold{}.h5\".format(target,nfold)\n\n            if mode_train == \"train\":\n                print(\"training start.\")\n                model = lgb.LGBMRegressor(**params)\n                verbose_eval = 100\n                model.fit(x_tr,\n                         y_tr,\n                         eval_set=[(x_tr,y_tr),(x_va,y_va)],\n                         callbacks=[\n                        early_stopping(stopping_rounds=50),  # 早期停止のコールバック\n                        log_evaluation(verbose_eval)]          # ログ表示のコールバック\n                         )\n                with open(filepath,\"wb\") as f:#h5は深層学習用拡張子\n                    pickle.dump(model,f,protocol=4)\n            else:\n                print(\"model load.\")\n                with open(filepath,\"rb\") as f:\n                    model = pickle.load(f)\n                print(\"Done.\")\n            \n            #validの推論値取得\n            y_va_pred = model.predict(x_va)\n            tmp_pred = pd.concat([\n                id_va,\n                pd.DataFrame({\"target\":target,\"nfold\":nfold,\"true\":y_va,\"pred\":y_va_pred}),\n            ],axis=1)\n            df_valid_pred = pd.concat([df_valid_pred, tmp_pred], axis=0, ignore_index=True)\n\n            #評価値の算出\n            metrics_va = mean_absolute_error(y_va,y_va_pred)\n            metrics.append([target,nfold,metrics_va])\n\n            #重要度の取得\n            tmp_imp = pd.DataFrame({\"col\":x_tr.columns,\"imp\":model.feature_importances_,\n                       \"target\":target,\"nfold\":nfold})\n            df_imp = pd.concat([df_imp,tmp_imp],axis=0,ignore_index=True)\n                               \n                    \n    print(\"-\"*20,\"result\",\"-\"*20)\n    #評価値\n    df_metrics = pd.DataFrame(metrics,columns=[\"target\",\"nfold\",\"mae\"])\n    print(\"MCMAE: {:.4f}\".format(df_metrics[\"mae\"].mean()))\n\n    #validの推論値\n    df_valid_pred_all = pd.pivot_table(df_valid_pred,index=\n                               [\"engagementMetricsDate\",\"playerId\",\"date_playerId\",\n                                \"date\",\"yearmonth\",\"playerForTestSetAndFuturePreds\"],\n                               columns=[\"target\",\"nfold\"],values=[\"true\",\"pred\"],aggfunc=np.sum)\n    df_valid_pred_all.columns = [\"{}_fold{}_{}\".format(j,k,i)for i,j,k in df_valid_pred_all.columns]\n    df_valid_pred_all = df_valid_pred_all.reset_index(drop=False)\n\n    return df_valid_pred_all, df_metrics, df_imp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:33.244247Z","iopub.execute_input":"2025-01-25T09:02:33.245134Z","iopub.status.idle":"2025-01-25T09:02:33.291529Z","shell.execute_reply.started":"2025-01-25T09:02:33.245078Z","shell.execute_reply":"2025-01-25T09:02:33.289342Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"#モデルを学習\nparams = {\n    'boosting_type':'gbdt',\n    'objective':'regression_l1',\n    'metric':'mean_absolute_error',\n    'learning_rate':0.05,\n    'num_leaves':32,\n    'subsample':0.7,\n    'subsample_freq':1,\n    'feature_fraction':0.8,\n    'min_data_in_leaf':50,\n    'min_sum_hessian_in_leaf':50,\n    'n_estimators':1000,\n    \"random_state\":123,\n    \"importance_type\":\"gain\",\n}\n\ndf_valid_pred,df_metrics,df_imp = train_lgb(x_train,\n                                           y_train,\n                                           id_train,\n                                           params,\n                                           list_nfold=[0,1,2],\n                                           mode_train=\"train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:02:33.300191Z","iopub.execute_input":"2025-01-25T09:02:33.300603Z","iopub.status.idle":"2025-01-25T09:07:09.816602Z","shell.execute_reply.started":"2025-01-25T09:02:33.300565Z","shell.execute_reply":"2025-01-25T09:07:09.815422Z"}},"outputs":[{"name":"stdout","text":"-------------------- target1 ,fold: 0 --------------------\n(752265, 10) (752265,) (752265, 6)\n(36797, 10) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014133 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3300\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 10\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.001289\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 0.50831\tvalid_1's l1: 1.29786\n[200]\ttraining's l1: 0.508183\tvalid_1's l1: 1.29768\n[300]\ttraining's l1: 0.508143\tvalid_1's l1: 1.29767\nEarly stopping, best iteration is:\n[258]\ttraining's l1: 0.508161\tvalid_1's l1: 1.29766\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target2 ,fold: 0 --------------------\n(752265, 10) (752265,) (752265, 6)\n(36797, 10) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014590 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3300\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 10\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.597907\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 1.82822\tvalid_1's l1: 2.4472\nEarly stopping, best iteration is:\n[61]\ttraining's l1: 1.83756\tvalid_1's l1: 2.44472\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target3 ,fold: 0 --------------------\n(752265, 10) (752265,) (752265, 6)\n(36797, 10) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014446 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3300\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 10\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.002002\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[17]\ttraining's l1: 0.578016\tvalid_1's l1: 0.877984\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target4 ,fold: 0 --------------------\n(752265, 10) (752265,) (752265, 6)\n(36797, 10) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013868 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3300\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 10\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.219419\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 0.795001\tvalid_1's l1: 1.25523\n[200]\ttraining's l1: 0.790734\tvalid_1's l1: 1.24924\n[300]\ttraining's l1: 0.790063\tvalid_1's l1: 1.24793\n[400]\ttraining's l1: 0.789686\tvalid_1's l1: 1.24706\n[500]\ttraining's l1: 0.789517\tvalid_1's l1: 1.2466\n[600]\ttraining's l1: 0.789432\tvalid_1's l1: 1.24618\n[700]\ttraining's l1: 0.789308\tvalid_1's l1: 1.24581\n[800]\ttraining's l1: 0.789256\tvalid_1's l1: 1.24554\n[900]\ttraining's l1: 0.789168\tvalid_1's l1: 1.24539\n[1000]\ttraining's l1: 0.789088\tvalid_1's l1: 1.24513\nDid not meet early stopping. Best iteration is:\n[1000]\ttraining's l1: 0.789088\tvalid_1's l1: 1.24513\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target1 ,fold: 1 --------------------\n(752265, 10) (752265,) (752265, 6)\n(35610, 10) (35610,) (35610, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014209 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3300\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 10\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.001159\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 0.540593\tvalid_1's l1: 1.19551\n[200]\ttraining's l1: 0.540381\tvalid_1's l1: 1.19536\n[300]\ttraining's l1: 0.540313\tvalid_1's l1: 1.19534\n[400]\ttraining's l1: 0.54027\tvalid_1's l1: 1.19526\nEarly stopping, best iteration is:\n[400]\ttraining's l1: 0.54027\tvalid_1's l1: 1.19526\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target2 ,fold: 1 --------------------\n(752265, 10) (752265,) (752265, 6)\n(35610, 10) (35610,) (35610, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014295 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3300\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 10\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.484206\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[38]\ttraining's l1: 1.73519\tvalid_1's l1: 2.15395\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target3 ,fold: 1 --------------------\n(752265, 10) (752265,) (752265, 6)\n(35610, 10) (35610,) (35610, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013825 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3300\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 10\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.001966\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[23]\ttraining's l1: 0.559224\tvalid_1's l1: 0.831668\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target4 ,fold: 1 --------------------\n(752265, 10) (752265,) (752265, 6)\n(35610, 10) (35610,) (35610, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013686 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3300\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 10\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.237834\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 0.830343\tvalid_1's l1: 1.66006\n[200]\ttraining's l1: 0.826925\tvalid_1's l1: 1.64909\n[300]\ttraining's l1: 0.82629\tvalid_1's l1: 1.64619\n[400]\ttraining's l1: 0.825918\tvalid_1's l1: 1.64452\n[500]\ttraining's l1: 0.82578\tvalid_1's l1: 1.64363\n[600]\ttraining's l1: 0.825687\tvalid_1's l1: 1.6428\n[700]\ttraining's l1: 0.825559\tvalid_1's l1: 1.642\n[800]\ttraining's l1: 0.825485\tvalid_1's l1: 1.64156\n[900]\ttraining's l1: 0.825413\tvalid_1's l1: 1.64108\n[1000]\ttraining's l1: 0.825375\tvalid_1's l1: 1.64062\nDid not meet early stopping. Best iteration is:\n[1000]\ttraining's l1: 0.825375\tvalid_1's l1: 1.64062\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target1 ,fold: 2 --------------------\n(752265, 10) (752265,) (752265, 6)\n(36797, 10) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014042 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3300\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 10\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.001059\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 0.56556\tvalid_1's l1: 1.11337\nEarly stopping, best iteration is:\n[54]\ttraining's l1: 0.565971\tvalid_1's l1: 1.11325\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target2 ,fold: 2 --------------------\n(752265, 10) (752265,) (752265, 6)\n(36797, 10) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013734 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3300\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 10\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.401123\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[24]\ttraining's l1: 1.67214\tvalid_1's l1: 1.79031\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target3 ,fold: 2 --------------------\n(752265, 10) (752265,) (752265, 6)\n(36797, 10) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013525 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3300\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 10\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.002010\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[30]\ttraining's l1: 0.562068\tvalid_1's l1: 0.760554\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target4 ,fold: 2 --------------------\n(752265, 10) (752265,) (752265, 6)\n(36797, 10) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014245 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 3300\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 10\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.258756\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[36]\ttraining's l1: 0.913552\tvalid_1's l1: 0.854185\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- result --------------------\nMCMAE: 1.3504\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"display(pd.pivot_table(df_metrics,index=\"nfold\",columns=\"target\",values=\"mae\",\n       aggfunc=np.mean,margins=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:07:09.818794Z","iopub.execute_input":"2025-01-25T09:07:09.819115Z","iopub.status.idle":"2025-01-25T09:07:09.856784Z","shell.execute_reply.started":"2025-01-25T09:07:09.819087Z","shell.execute_reply":"2025-01-25T09:07:09.855719Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"target    target1    target2    target3    target4        All\nnfold                                                        \n0          1.2977     2.4447     0.8780     1.2451     1.4664\n1          1.1953     2.1539     0.8317     1.6406     1.4554\n2          1.1133     1.7903     0.7606     0.8542     1.1296\nAll        1.2021     2.1297     0.8234     1.2466     1.3504","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>target</th>\n      <th>target1</th>\n      <th>target2</th>\n      <th>target3</th>\n      <th>target4</th>\n      <th>All</th>\n    </tr>\n    <tr>\n      <th>nfold</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.2977</td>\n      <td>2.4447</td>\n      <td>0.8780</td>\n      <td>1.2451</td>\n      <td>1.4664</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.1953</td>\n      <td>2.1539</td>\n      <td>0.8317</td>\n      <td>1.6406</td>\n      <td>1.4554</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.1133</td>\n      <td>1.7903</td>\n      <td>0.7606</td>\n      <td>0.8542</td>\n      <td>1.1296</td>\n    </tr>\n    <tr>\n      <th>All</th>\n      <td>1.2021</td>\n      <td>2.1297</td>\n      <td>0.8234</td>\n      <td>1.2466</td>\n      <td>1.3504</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"df_imp.groupby([\"col\"])[\"imp\"].agg([\"mean\",\"std\"]).sort_values(\"mean\",ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:07:09.857990Z","iopub.execute_input":"2025-01-25T09:07:09.858400Z","iopub.status.idle":"2025-01-25T09:07:09.883682Z","shell.execute_reply.started":"2025-01-25T09:07:09.858361Z","shell.execute_reply":"2025-01-25T09:07:09.882410Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                       mean          std\ncol                                                     \nplayerId                       4976980.5395 6102371.1341\nplayerForTestSetAndFuturePreds 1115074.5464 1091298.8384\nbirthCity                       741457.7171 1058010.6632\nprimaryPositionCode             110792.2785  167555.0234\ndayofweek                        78879.0470  140714.7657\nprimaryPositionName              33697.4310   38239.7619\nweight                           20633.3897   31551.4583\nheightInches                     19410.1825   34119.9997\nbirthStateProvince                7714.1863   13322.8164\nbirthCountry                      2933.4399    5114.6680","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n    <tr>\n      <th>col</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>playerId</th>\n      <td>4976980.5395</td>\n      <td>6102371.1341</td>\n    </tr>\n    <tr>\n      <th>playerForTestSetAndFuturePreds</th>\n      <td>1115074.5464</td>\n      <td>1091298.8384</td>\n    </tr>\n    <tr>\n      <th>birthCity</th>\n      <td>741457.7171</td>\n      <td>1058010.6632</td>\n    </tr>\n    <tr>\n      <th>primaryPositionCode</th>\n      <td>110792.2785</td>\n      <td>167555.0234</td>\n    </tr>\n    <tr>\n      <th>dayofweek</th>\n      <td>78879.0470</td>\n      <td>140714.7657</td>\n    </tr>\n    <tr>\n      <th>primaryPositionName</th>\n      <td>33697.4310</td>\n      <td>38239.7619</td>\n    </tr>\n    <tr>\n      <th>weight</th>\n      <td>20633.3897</td>\n      <td>31551.4583</td>\n    </tr>\n    <tr>\n      <th>heightInches</th>\n      <td>19410.1825</td>\n      <td>34119.9997</td>\n    </tr>\n    <tr>\n      <th>birthStateProvince</th>\n      <td>7714.1863</td>\n      <td>13322.8164</td>\n    </tr>\n    <tr>\n      <th>birthCountry</th>\n      <td>2933.4399</td>\n      <td>5114.6680</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"#特徴量エンジニアリング\n#選手ごとのステータス\ndf_rosters = extract_data(train,col=\"rosters\")#jsonからdfへ変換","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:07:09.884996Z","iopub.execute_input":"2025-01-25T09:07:09.885339Z","iopub.status.idle":"2025-01-25T09:07:26.160105Z","shell.execute_reply.started":"2025-01-25T09:07:09.885297Z","shell.execute_reply":"2025-01-25T09:07:26.158594Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"df_rosters.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:07:26.162033Z","iopub.execute_input":"2025-01-25T09:07:26.162501Z","iopub.status.idle":"2025-01-25T09:07:26.174179Z","shell.execute_reply.started":"2025-01-25T09:07:26.162460Z","shell.execute_reply":"2025-01-25T09:07:26.172953Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"   playerId    gameDate  teamId statusCode  status\n0    430935  2020-04-01     144          A  Active\n1    435062  2020-04-01     120          A  Active\n2    444489  2020-04-01     158          A  Active\n3    445276  2020-04-01     119          A  Active\n4    446308  2020-04-01     138          A  Active","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>playerId</th>\n      <th>gameDate</th>\n      <th>teamId</th>\n      <th>statusCode</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>430935</td>\n      <td>2020-04-01</td>\n      <td>144</td>\n      <td>A</td>\n      <td>Active</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>435062</td>\n      <td>2020-04-01</td>\n      <td>120</td>\n      <td>A</td>\n      <td>Active</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>444489</td>\n      <td>2020-04-01</td>\n      <td>158</td>\n      <td>A</td>\n      <td>Active</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>445276</td>\n      <td>2020-04-01</td>\n      <td>119</td>\n      <td>A</td>\n      <td>Active</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>446308</td>\n      <td>2020-04-01</td>\n      <td>138</td>\n      <td>A</td>\n      <td>Active</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"df_rosters = df_rosters.rename(columns={\"gameDate\":\"date\"})\ndf_rosters[\"date\"] = pd.to_datetime(df_rosters[\"date\"],format=\"%Y-%m-%d\")\n\n#追加するカラムリストの作成（dateとplayerIDは結合キー）\ncol_rosters = [\"teamId\",\"statusCode\",\"status\"]\n\ndf_rosters.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:07:26.175189Z","iopub.execute_input":"2025-01-25T09:07:26.175496Z","iopub.status.idle":"2025-01-25T09:07:26.544207Z","shell.execute_reply.started":"2025-01-25T09:07:26.175469Z","shell.execute_reply":"2025-01-25T09:07:26.543164Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"   playerId       date  teamId statusCode  status\n0    430935 2020-04-01     144          A  Active\n1    435062 2020-04-01     120          A  Active\n2    444489 2020-04-01     158          A  Active\n3    445276 2020-04-01     119          A  Active\n4    446308 2020-04-01     138          A  Active","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>playerId</th>\n      <th>date</th>\n      <th>teamId</th>\n      <th>statusCode</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>430935</td>\n      <td>2020-04-01</td>\n      <td>144</td>\n      <td>A</td>\n      <td>Active</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>435062</td>\n      <td>2020-04-01</td>\n      <td>120</td>\n      <td>A</td>\n      <td>Active</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>444489</td>\n      <td>2020-04-01</td>\n      <td>158</td>\n      <td>A</td>\n      <td>Active</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>445276</td>\n      <td>2020-04-01</td>\n      <td>119</td>\n      <td>A</td>\n      <td>Active</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>446308</td>\n      <td>2020-04-01</td>\n      <td>138</td>\n      <td>A</td>\n      <td>Active</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"#ラグ特徴量の作成（1か月前の統計量を特徴量として利用）\n#データの前処理\ndf_agg_target = df_train.groupby([\"yearmonth\",\"playerId\"])[[\"target1\",\"target2\",\n                                                            \"target3\",\"target4\"]].agg([\"mean\",\"median\",\"std\",\"min\",\"max\"])\ndf_agg_target.columns = [\"{}_{}\".format(i,j) for i,j in df_agg_target.columns]\ndf_agg_target = df_agg_target.reset_index(drop=False)\ndf_agg_target.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:07:26.545380Z","iopub.execute_input":"2025-01-25T09:07:26.545782Z","iopub.status.idle":"2025-01-25T09:07:26.927380Z","shell.execute_reply.started":"2025-01-25T09:07:26.545743Z","shell.execute_reply":"2025-01-25T09:07:26.926001Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"  yearmonth  playerId  target1_mean  target1_median  target1_std  target1_min  \\\n0   2020-04    112526        0.8834          0.0647       2.9618       0.0224   \n1   2020-04    134181        2.9999          0.2175      10.9845       0.0645   \n2   2020-04    279571        0.0003          0.0000       0.0006       0.0000   \n3   2020-04    282332        0.1413          0.0748       0.1702       0.0223   \n4   2020-04    400085        1.9515          0.6949       3.3399       0.0947   \n\n   target1_max  target2_mean  target2_median  target2_std  ...  target3_mean  \\\n0      15.9780       10.8110         10.4352       5.3041  ...        0.2894   \n1      58.4642       14.7861         11.9902      13.2362  ...       10.6877   \n2       0.0016        0.3970          0.3435       0.2787  ...        0.0004   \n3       0.7391        7.8652          7.7711       4.0453  ...        0.3794   \n4      17.0843       30.0941         27.2808      16.4382  ...       13.3777   \n\n   target3_median  target3_std  target3_min  target3_max  target4_mean  \\\n0          0.1752       0.3478       0.0216       1.6761       21.1961   \n1          0.9546      24.8149       0.0348     100.0000       12.0298   \n2          0.0000       0.0013       0.0000       0.0060        0.2895   \n3          0.3382       0.2484       0.0501       0.9882       11.3540   \n4          1.8486      26.4342       0.2183     100.0000       50.7711   \n\n   target4_median  target4_std  target4_min  target4_max  \n0         20.7913      12.6768       0.6305      51.3299  \n1         11.6739       6.2926       0.5478      24.3902  \n2          0.2481       0.1986       0.0097       0.7000  \n3         10.0147       6.1022       0.5633      23.4455  \n4         47.0509      29.4601       2.5769     100.0000  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>yearmonth</th>\n      <th>playerId</th>\n      <th>target1_mean</th>\n      <th>target1_median</th>\n      <th>target1_std</th>\n      <th>target1_min</th>\n      <th>target1_max</th>\n      <th>target2_mean</th>\n      <th>target2_median</th>\n      <th>target2_std</th>\n      <th>...</th>\n      <th>target3_mean</th>\n      <th>target3_median</th>\n      <th>target3_std</th>\n      <th>target3_min</th>\n      <th>target3_max</th>\n      <th>target4_mean</th>\n      <th>target4_median</th>\n      <th>target4_std</th>\n      <th>target4_min</th>\n      <th>target4_max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-04</td>\n      <td>112526</td>\n      <td>0.8834</td>\n      <td>0.0647</td>\n      <td>2.9618</td>\n      <td>0.0224</td>\n      <td>15.9780</td>\n      <td>10.8110</td>\n      <td>10.4352</td>\n      <td>5.3041</td>\n      <td>...</td>\n      <td>0.2894</td>\n      <td>0.1752</td>\n      <td>0.3478</td>\n      <td>0.0216</td>\n      <td>1.6761</td>\n      <td>21.1961</td>\n      <td>20.7913</td>\n      <td>12.6768</td>\n      <td>0.6305</td>\n      <td>51.3299</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-04</td>\n      <td>134181</td>\n      <td>2.9999</td>\n      <td>0.2175</td>\n      <td>10.9845</td>\n      <td>0.0645</td>\n      <td>58.4642</td>\n      <td>14.7861</td>\n      <td>11.9902</td>\n      <td>13.2362</td>\n      <td>...</td>\n      <td>10.6877</td>\n      <td>0.9546</td>\n      <td>24.8149</td>\n      <td>0.0348</td>\n      <td>100.0000</td>\n      <td>12.0298</td>\n      <td>11.6739</td>\n      <td>6.2926</td>\n      <td>0.5478</td>\n      <td>24.3902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-04</td>\n      <td>279571</td>\n      <td>0.0003</td>\n      <td>0.0000</td>\n      <td>0.0006</td>\n      <td>0.0000</td>\n      <td>0.0016</td>\n      <td>0.3970</td>\n      <td>0.3435</td>\n      <td>0.2787</td>\n      <td>...</td>\n      <td>0.0004</td>\n      <td>0.0000</td>\n      <td>0.0013</td>\n      <td>0.0000</td>\n      <td>0.0060</td>\n      <td>0.2895</td>\n      <td>0.2481</td>\n      <td>0.1986</td>\n      <td>0.0097</td>\n      <td>0.7000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-04</td>\n      <td>282332</td>\n      <td>0.1413</td>\n      <td>0.0748</td>\n      <td>0.1702</td>\n      <td>0.0223</td>\n      <td>0.7391</td>\n      <td>7.8652</td>\n      <td>7.7711</td>\n      <td>4.0453</td>\n      <td>...</td>\n      <td>0.3794</td>\n      <td>0.3382</td>\n      <td>0.2484</td>\n      <td>0.0501</td>\n      <td>0.9882</td>\n      <td>11.3540</td>\n      <td>10.0147</td>\n      <td>6.1022</td>\n      <td>0.5633</td>\n      <td>23.4455</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-04</td>\n      <td>400085</td>\n      <td>1.9515</td>\n      <td>0.6949</td>\n      <td>3.3399</td>\n      <td>0.0947</td>\n      <td>17.0843</td>\n      <td>30.0941</td>\n      <td>27.2808</td>\n      <td>16.4382</td>\n      <td>...</td>\n      <td>13.3777</td>\n      <td>1.8486</td>\n      <td>26.4342</td>\n      <td>0.2183</td>\n      <td>100.0000</td>\n      <td>50.7711</td>\n      <td>47.0509</td>\n      <td>29.4601</td>\n      <td>2.5769</td>\n      <td>100.0000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"#ラグ特徴量の作成\n#年月でソート（時系列順に並んでいないとシフト時におかしくなるので）\ndf_agg_target = df_agg_target.sort_values(\"yearmonth\").reset_index(drop=True)\n\n#yearmonthを1か月シフトして過去にする\ndf_agg_target[\"yearmonth\"] = df_agg_target.groupby([\"playerId\"])[\"yearmonth\"].shift(-1)\n#yearmonthの欠損値を[2021-08]で埋める\ndf_agg_target[\"yearmonth\"] = df_agg_target[\"yearmonth\"].fillna(\"2021-08\")\n\n#集計値がラグ特徴量と分かるようにカラム名を変更\ndf_agg_target.columns = [col + \"_lag1month\" if col not in [\"playerId\",\"yearmonth\"]else\n                        col for col in df_agg_target.columns]\n\n#追加したカラムリストを作成\ncol_agg_target = list(df_agg_target.columns[df_agg_target.columns.str.contains(\"lag1month\")])\ndf_agg_target.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:07:26.928374Z","iopub.execute_input":"2025-01-25T09:07:26.928992Z","iopub.status.idle":"2025-01-25T09:07:26.983321Z","shell.execute_reply.started":"2025-01-25T09:07:26.928947Z","shell.execute_reply":"2025-01-25T09:07:26.982103Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"  yearmonth  playerId  target1_mean_lag1month  target1_median_lag1month  \\\n0   2020-05    112526                  0.8834                    0.0647   \n1   2020-05    628318                  0.0003                    0.0000   \n2   2020-05    628317                  0.0747                    0.0327   \n3   2020-05    627894                  0.0004                    0.0000   \n4   2020-05    627500                  0.0004                    0.0000   \n\n   target1_std_lag1month  target1_min_lag1month  target1_max_lag1month  \\\n0                 2.9618                 0.0224                15.9780   \n1                 0.0016                 0.0000                 0.0088   \n2                 0.1005                 0.0139                 0.4201   \n3                 0.0008                 0.0000                 0.0037   \n4                 0.0019                 0.0000                 0.0104   \n\n   target2_mean_lag1month  target2_median_lag1month  target2_std_lag1month  \\\n0                 10.8110                   10.4352                 5.3041   \n1                  0.3717                    0.3519                 0.2857   \n2                 10.7568                    9.6495                 4.7834   \n3                  1.2347                    1.1066                 0.6663   \n4                  0.2940                    0.1969                 0.3396   \n\n   ...  target3_mean_lag1month  target3_median_lag1month  \\\n0  ...                  0.2894                    0.1752   \n1  ...                  0.0000                    0.0000   \n2  ...                  0.0816                    0.0746   \n3  ...                  0.0020                    0.0000   \n4  ...                  0.0000                    0.0000   \n\n   target3_std_lag1month  target3_min_lag1month  target3_max_lag1month  \\\n0                 0.3478                 0.0216                 1.6761   \n1                 0.0000                 0.0000                 0.0000   \n2                 0.0462                 0.0116                 0.1811   \n3                 0.0035                 0.0000                 0.0157   \n4                 0.0001                 0.0000                 0.0005   \n\n   target4_mean_lag1month  target4_median_lag1month  target4_std_lag1month  \\\n0                 21.1961                   20.7913                12.6768   \n1                  0.4519                    0.4173                 0.2852   \n2                  3.2524                    2.9701                 1.8610   \n3                  0.3802                    0.3303                 0.2352   \n4                  0.2036                    0.1609                 0.1362   \n\n   target4_min_lag1month  target4_max_lag1month  \n0                 0.6305                51.3299  \n1                 0.0126                 1.1760  \n2                 0.1119                 6.8816  \n3                 0.0165                 0.9146  \n4                 0.0117                 0.5662  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>yearmonth</th>\n      <th>playerId</th>\n      <th>target1_mean_lag1month</th>\n      <th>target1_median_lag1month</th>\n      <th>target1_std_lag1month</th>\n      <th>target1_min_lag1month</th>\n      <th>target1_max_lag1month</th>\n      <th>target2_mean_lag1month</th>\n      <th>target2_median_lag1month</th>\n      <th>target2_std_lag1month</th>\n      <th>...</th>\n      <th>target3_mean_lag1month</th>\n      <th>target3_median_lag1month</th>\n      <th>target3_std_lag1month</th>\n      <th>target3_min_lag1month</th>\n      <th>target3_max_lag1month</th>\n      <th>target4_mean_lag1month</th>\n      <th>target4_median_lag1month</th>\n      <th>target4_std_lag1month</th>\n      <th>target4_min_lag1month</th>\n      <th>target4_max_lag1month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-05</td>\n      <td>112526</td>\n      <td>0.8834</td>\n      <td>0.0647</td>\n      <td>2.9618</td>\n      <td>0.0224</td>\n      <td>15.9780</td>\n      <td>10.8110</td>\n      <td>10.4352</td>\n      <td>5.3041</td>\n      <td>...</td>\n      <td>0.2894</td>\n      <td>0.1752</td>\n      <td>0.3478</td>\n      <td>0.0216</td>\n      <td>1.6761</td>\n      <td>21.1961</td>\n      <td>20.7913</td>\n      <td>12.6768</td>\n      <td>0.6305</td>\n      <td>51.3299</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-05</td>\n      <td>628318</td>\n      <td>0.0003</td>\n      <td>0.0000</td>\n      <td>0.0016</td>\n      <td>0.0000</td>\n      <td>0.0088</td>\n      <td>0.3717</td>\n      <td>0.3519</td>\n      <td>0.2857</td>\n      <td>...</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.4519</td>\n      <td>0.4173</td>\n      <td>0.2852</td>\n      <td>0.0126</td>\n      <td>1.1760</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-05</td>\n      <td>628317</td>\n      <td>0.0747</td>\n      <td>0.0327</td>\n      <td>0.1005</td>\n      <td>0.0139</td>\n      <td>0.4201</td>\n      <td>10.7568</td>\n      <td>9.6495</td>\n      <td>4.7834</td>\n      <td>...</td>\n      <td>0.0816</td>\n      <td>0.0746</td>\n      <td>0.0462</td>\n      <td>0.0116</td>\n      <td>0.1811</td>\n      <td>3.2524</td>\n      <td>2.9701</td>\n      <td>1.8610</td>\n      <td>0.1119</td>\n      <td>6.8816</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-05</td>\n      <td>627894</td>\n      <td>0.0004</td>\n      <td>0.0000</td>\n      <td>0.0008</td>\n      <td>0.0000</td>\n      <td>0.0037</td>\n      <td>1.2347</td>\n      <td>1.1066</td>\n      <td>0.6663</td>\n      <td>...</td>\n      <td>0.0020</td>\n      <td>0.0000</td>\n      <td>0.0035</td>\n      <td>0.0000</td>\n      <td>0.0157</td>\n      <td>0.3802</td>\n      <td>0.3303</td>\n      <td>0.2352</td>\n      <td>0.0165</td>\n      <td>0.9146</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-05</td>\n      <td>627500</td>\n      <td>0.0004</td>\n      <td>0.0000</td>\n      <td>0.0019</td>\n      <td>0.0000</td>\n      <td>0.0104</td>\n      <td>0.2940</td>\n      <td>0.1969</td>\n      <td>0.3396</td>\n      <td>...</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0001</td>\n      <td>0.0000</td>\n      <td>0.0005</td>\n      <td>0.2036</td>\n      <td>0.1609</td>\n      <td>0.1362</td>\n      <td>0.0117</td>\n      <td>0.5662</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"#学習用データセットの作成\ndf_train = pd.merge(df_engagement,df_players,on=[\"playerId\"],how=\"left\")\ndf_train = pd.merge(df_train,df_rosters,on=[\"date\",\"playerId\"],how=\"left\")\ndf_train = pd.merge(df_train,df_agg_target,on=[\"playerId\",\"yearmonth\"],how=\"left\")\n\n#説明変数と目的変数の作成\nx_train = df_train[[\n    \"playerId\",\"dayofweek\",\n    \"birthCity\",\"birthStateProvince\",\"birthCountry\",\"heightInches\",\"weight\",\n    \"primaryPositionCode\",\"primaryPositionName\",\"playerForTestSetAndFuturePreds\"\n]+ col_rosters + col_agg_target]\n\ny_train = df_train[[\"target1\",\"target2\",\"target3\",\"target4\"]]\nid_train = df_train[[\"engagementMetricsDate\",\"playerId\",\"date_playerId\",\"date\",\n                    \"yearmonth\",\"playerForTestSetAndFuturePreds\"]]\n\n#カテゴリ変数をcategory型に変換\nfor col in [\"playerId\",\"dayofweek\",\"birthCity\",\"birthStateProvince\",\n           \"birthCountry\",\"primaryPositionCode\",\"primaryPositionName\"] + col_rosters:\n    x_train[col] = x_train[col].astype(\"category\")\n\nprint(x_train.shape,y_train.shape,id_train.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:07:26.984596Z","iopub.execute_input":"2025-01-25T09:07:26.985040Z","iopub.status.idle":"2025-01-25T09:07:30.850206Z","shell.execute_reply.started":"2025-01-25T09:07:26.985000Z","shell.execute_reply":"2025-01-25T09:07:30.849162Z"}},"outputs":[{"name":"stdout","text":"(1003707, 33) (1003707, 4) (1003707, 6)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"#モデル学習\n#モデルを学習\nparams = {\n    'boosting_type':'gbdt',\n    'objective':'regression_l1',\n    'metric':'mean_absolute_error',\n    'learning_rate':0.05,\n    'num_leaves':32,\n    'subsample':0.7,\n    'subsample_freq':1,\n    'feature_fraction':0.8,\n    'min_data_in_leaf':50,\n    'min_sum_hessian_in_leaf':50,\n    'n_estimators':1000,\n    \"random_state\":123,\n    \"importance_type\":\"gain\",\n}\n\ndf_valid_pred,df_metrics,df_imp = train_lgb(x_train,\n                                           y_train,\n                                           id_train,\n                                           params,\n                                           list_nfold=[0,1,2],\n                                           mode_train=\"train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:07:30.851605Z","iopub.execute_input":"2025-01-25T09:07:30.851926Z","iopub.status.idle":"2025-01-25T09:12:51.462405Z","shell.execute_reply.started":"2025-01-25T09:07:30.851887Z","shell.execute_reply":"2025-01-25T09:12:51.461248Z"}},"outputs":[{"name":"stdout","text":"-------------------- target1 ,fold: 0 --------------------\n(752265, 33) (752265,) (752265, 6)\n(36797, 33) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069228 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 8454\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 33\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.001289\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 0.504414\tvalid_1's l1: 1.28763\n[200]\ttraining's l1: 0.504261\tvalid_1's l1: 1.28723\nEarly stopping, best iteration is:\n[167]\ttraining's l1: 0.504269\tvalid_1's l1: 1.28723\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target2 ,fold: 0 --------------------\n(752265, 33) (752265,) (752265, 6)\n(36797, 33) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074377 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 8454\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 33\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.597907\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 1.57256\tvalid_1's l1: 2.19101\nEarly stopping, best iteration is:\n[111]\ttraining's l1: 1.56256\tvalid_1's l1: 2.18647\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target3 ,fold: 0 --------------------\n(752265, 33) (752265,) (752265, 6)\n(36797, 33) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063416 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 8454\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 33\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.002002\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[25]\ttraining's l1: 0.57287\tvalid_1's l1: 0.873065\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target4 ,fold: 0 --------------------\n(752265, 33) (752265,) (752265, 6)\n(36797, 33) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077416 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 8454\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 33\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.219419\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 0.754354\tvalid_1's l1: 1.21622\n[200]\ttraining's l1: 0.733873\tvalid_1's l1: 1.20694\nEarly stopping, best iteration is:\n[221]\ttraining's l1: 0.731062\tvalid_1's l1: 1.20601\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target1 ,fold: 1 --------------------\n(752265, 33) (752265,) (752265, 6)\n(35610, 33) (35610,) (35610, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062298 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 8455\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 33\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.001159\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 0.536875\tvalid_1's l1: 1.18295\n[200]\ttraining's l1: 0.536551\tvalid_1's l1: 1.18249\n[300]\ttraining's l1: 0.536405\tvalid_1's l1: 1.18175\n[400]\ttraining's l1: 0.536308\tvalid_1's l1: 1.18153\nEarly stopping, best iteration is:\n[353]\ttraining's l1: 0.536332\tvalid_1's l1: 1.18149\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target2 ,fold: 1 --------------------\n(752265, 33) (752265,) (752265, 6)\n(35610, 33) (35610,) (35610, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073083 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 8455\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 33\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.484206\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 1.54274\tvalid_1's l1: 1.89609\nEarly stopping, best iteration is:\n[92]\ttraining's l1: 1.54718\tvalid_1's l1: 1.89533\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target3 ,fold: 1 --------------------\n(752265, 33) (752265,) (752265, 6)\n(35610, 33) (35610,) (35610, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065092 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 8455\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 33\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.001966\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 0.552147\tvalid_1's l1: 0.825292\n[200]\ttraining's l1: 0.55167\tvalid_1's l1: 0.825022\n[300]\ttraining's l1: 0.551507\tvalid_1's l1: 0.824957\nEarly stopping, best iteration is:\n[285]\ttraining's l1: 0.551507\tvalid_1's l1: 0.824956\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target4 ,fold: 1 --------------------\n(752265, 33) (752265,) (752265, 6)\n(35610, 33) (35610,) (35610, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070548 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 8455\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 33\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.237834\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 0.793389\tvalid_1's l1: 1.56965\n[200]\ttraining's l1: 0.775425\tvalid_1's l1: 1.55899\n[300]\ttraining's l1: 0.768815\tvalid_1's l1: 1.55675\n[400]\ttraining's l1: 0.766109\tvalid_1's l1: 1.55418\n[500]\ttraining's l1: 0.765981\tvalid_1's l1: 1.55416\n[600]\ttraining's l1: 0.765879\tvalid_1's l1: 1.55412\n[700]\ttraining's l1: 0.765223\tvalid_1's l1: 1.55389\nEarly stopping, best iteration is:\n[743]\ttraining's l1: 0.764962\tvalid_1's l1: 1.55376\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target1 ,fold: 2 --------------------\n(752265, 33) (752265,) (752265, 6)\n(36797, 33) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072198 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 8452\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 33\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.001059\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 0.561311\tvalid_1's l1: 1.09946\n[200]\ttraining's l1: 0.561104\tvalid_1's l1: 1.099\nEarly stopping, best iteration is:\n[247]\ttraining's l1: 0.560954\tvalid_1's l1: 1.09868\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target2 ,fold: 2 --------------------\n(752265, 33) (752265,) (752265, 6)\n(36797, 33) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069273 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 8452\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 33\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.401123\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 1.47175\tvalid_1's l1: 1.59312\nEarly stopping, best iteration is:\n[95]\ttraining's l1: 1.47473\tvalid_1's l1: 1.59247\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target3 ,fold: 2 --------------------\n(752265, 33) (752265,) (752265, 6)\n(36797, 33) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091526 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 8452\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 33\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.002010\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's l1: 0.556857\tvalid_1's l1: 0.753011\n[200]\ttraining's l1: 0.55638\tvalid_1's l1: 0.752608\nEarly stopping, best iteration is:\n[247]\ttraining's l1: 0.556247\tvalid_1's l1: 0.752433\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- target4 ,fold: 2 --------------------\n(752265, 33) (752265,) (752265, 6)\n(36797, 33) (36797,) (36797, 6)\ntraining start.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066944 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 8452\n[LightGBM] [Info] Number of data points in the train set: 752265, number of used features: 33\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n[LightGBM] [Info] Start training from score 0.258756\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[16]\ttraining's l1: 0.949953\tvalid_1's l1: 0.881828\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n-------------------- result --------------------\nMCMAE: 1.2778\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"display(pd.pivot_table(df_metrics,index=\"nfold\",columns=\"target\",values=\"mae\",\n       aggfunc=np.mean,margins=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:12:51.463836Z","iopub.execute_input":"2025-01-25T09:12:51.464262Z","iopub.status.idle":"2025-01-25T09:12:51.499676Z","shell.execute_reply.started":"2025-01-25T09:12:51.464231Z","shell.execute_reply":"2025-01-25T09:12:51.498669Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"target    target1    target2    target3    target4        All\nnfold                                                        \n0          1.2872     2.1865     0.8731     1.2060     1.3882\n1          1.1815     1.8953     0.8250     1.5538     1.3639\n2          1.0987     1.5925     0.7524     0.8818     1.0814\nAll        1.1891     1.8914     0.8168     1.2139     1.2778","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>target</th>\n      <th>target1</th>\n      <th>target2</th>\n      <th>target3</th>\n      <th>target4</th>\n      <th>All</th>\n    </tr>\n    <tr>\n      <th>nfold</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.2872</td>\n      <td>2.1865</td>\n      <td>0.8731</td>\n      <td>1.2060</td>\n      <td>1.3882</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.1815</td>\n      <td>1.8953</td>\n      <td>0.8250</td>\n      <td>1.5538</td>\n      <td>1.3639</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0987</td>\n      <td>1.5925</td>\n      <td>0.7524</td>\n      <td>0.8818</td>\n      <td>1.0814</td>\n    </tr>\n    <tr>\n      <th>All</th>\n      <td>1.1891</td>\n      <td>1.8914</td>\n      <td>0.8168</td>\n      <td>1.2139</td>\n      <td>1.2778</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"#モデルチューニング\n\n#目的変数間の相関係数を算出\ndf_engagement[[\"target1\",\"target2\",\"target3\",\"target4\"]].corr()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:12:51.500746Z","iopub.execute_input":"2025-01-25T09:12:51.501218Z","iopub.status.idle":"2025-01-25T09:12:51.578750Z","shell.execute_reply.started":"2025-01-25T09:12:51.501171Z","shell.execute_reply":"2025-01-25T09:12:51.577410Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"           target1    target2    target3    target4\ntarget1     1.0000     0.3529     0.3833     0.3252\ntarget2     0.3529     1.0000     0.3660     0.4988\ntarget3     0.3833     0.3660     1.0000     0.3229\ntarget4     0.3252     0.4988     0.3229     1.0000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target1</th>\n      <th>target2</th>\n      <th>target3</th>\n      <th>target4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>target1</th>\n      <td>1.0000</td>\n      <td>0.3529</td>\n      <td>0.3833</td>\n      <td>0.3252</td>\n    </tr>\n    <tr>\n      <th>target2</th>\n      <td>0.3529</td>\n      <td>1.0000</td>\n      <td>0.3660</td>\n      <td>0.4988</td>\n    </tr>\n    <tr>\n      <th>target3</th>\n      <td>0.3833</td>\n      <td>0.3660</td>\n      <td>1.0000</td>\n      <td>0.3229</td>\n    </tr>\n    <tr>\n      <th>target4</th>\n      <td>0.3252</td>\n      <td>0.4988</td>\n      <td>0.3229</td>\n      <td>1.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"#目的変数同士に相関があるため、マルチタスクによる精度向上が期待できる\n#そこで、ニューラルネットワークを用いる\nfrom sklearn.preprocessing import LabelEncoder\n\nimport tensorflow\nfrom tensorflow.keras.models import Sequential,Model\nfrom tensorflow.keras.layers import Input,Dense,Dropout,BatchNormalization,Activation,Concatenate\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau,LearningRateScheduler\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.layers import Embedding,Flatten","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:12:51.580024Z","iopub.execute_input":"2025-01-25T09:12:51.580334Z","iopub.status.idle":"2025-01-25T09:13:04.267586Z","shell.execute_reply.started":"2025-01-25T09:12:51.580308Z","shell.execute_reply":"2025-01-25T09:13:04.266204Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"#説明変数と目的変数の作成\nx_train = df_train[[\n    \"playerId\",\"dayofweek\",\n    \"birthCity\",\"birthStateProvince\",\"birthCountry\",\"heightInches\",\"weight\",\n    \"primaryPositionCode\",\"primaryPositionName\",\"playerForTestSetAndFuturePreds\"\n]+ col_rosters + col_agg_target]\n\ny_train = df_train[[\"target1\",\"target2\",\"target3\",\"target4\"]]\nid_train = df_train[[\"engagementMetricsDate\",\"playerId\",\"date_playerId\",\"date\",\n                    \"yearmonth\",\"playerForTestSetAndFuturePreds\"]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:13:04.268874Z","iopub.execute_input":"2025-01-25T09:13:04.269823Z","iopub.status.idle":"2025-01-25T09:13:04.529842Z","shell.execute_reply.started":"2025-01-25T09:13:04.269789Z","shell.execute_reply":"2025-01-25T09:13:04.528859Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"#数値とカテゴリ変数のカラムリストを作成\ncol_num = [\"heightInches\",\"weight\",\"playerForTestSetAndFuturePreds\"] + col_agg_target\ncol_cat = [\"playerId\",\"dayofweek\",\"birthCity\",\"birthStateProvince\",\"birthCountry\",\n          \"primaryPositionCode\",\"primaryPositionName\"] + col_rosters\nprint(len(col_num),len(col_cat))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:13:04.531127Z","iopub.execute_input":"2025-01-25T09:13:04.531550Z","iopub.status.idle":"2025-01-25T09:13:04.538579Z","shell.execute_reply.started":"2025-01-25T09:13:04.531508Z","shell.execute_reply":"2025-01-25T09:13:04.536975Z"}},"outputs":[{"name":"stdout","text":"23 10\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"#数値データの欠損値補間・正規化\ndict_num = {}\nfor col in col_num:\n    print(col)\n    #欠損値補間：0で埋める\n    value_fillna = 0\n    x_train[col] = x_train[col].fillna(value_fillna)\n\n    #正規化（0~1になるように変換）\n    value_min = x_train[col].min()\n    value_max = x_train[col].max()\n    x_train[col] = (x_train[col] - value_min) / (value_max - value_min)\n\n    #testデータにも適応出来るように保存\n    dict_num[col] = {}\n    dict_num[col][\"fillna\"] = value_fillna\n    dict_num[col][\"min\"] = value_min\n    dict_num[col][\"max\"] = value_max\n\nprint(\"Done.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:13:04.540408Z","iopub.execute_input":"2025-01-25T09:13:04.540892Z","iopub.status.idle":"2025-01-25T09:13:04.942620Z","shell.execute_reply.started":"2025-01-25T09:13:04.540848Z","shell.execute_reply":"2025-01-25T09:13:04.941349Z"}},"outputs":[{"name":"stdout","text":"heightInches\nweight\nplayerForTestSetAndFuturePreds\ntarget1_mean_lag1month\ntarget1_median_lag1month\ntarget1_std_lag1month\ntarget1_min_lag1month\ntarget1_max_lag1month\ntarget2_mean_lag1month\ntarget2_median_lag1month\ntarget2_std_lag1month\ntarget2_min_lag1month\ntarget2_max_lag1month\ntarget3_mean_lag1month\ntarget3_median_lag1month\ntarget3_std_lag1month\ntarget3_min_lag1month\ntarget3_max_lag1month\ntarget4_mean_lag1month\ntarget4_median_lag1month\ntarget4_std_lag1month\ntarget4_min_lag1month\ntarget4_max_lag1month\nDone.\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"#カテゴリ変数の欠損値補間・数値化\n#埋め込み層ありのネットワークモデル用\ndict_cat = {}\nfor col in col_cat:\n    print(col)\n    #欠損値補間：unknownで埋める\n    value_fillna = \"unknown\"\n    x_train[col] = x_train[col].fillna(value_fillna)\n\n    #str型に変換\n    x_train[col] = x_train[col].astype(str)\n\n    #ラベルエンコーダー：0から始まる整数に変換\n    le = LabelEncoder()\n    le.fit(x_train[col])\n    list_label = sorted(list(set(le.classes_) | set([\"unknown\"])))\n    map_label = {j:i for i,j in enumerate(list_label)}\n    x_train[col] = x_train[col].map(map_label)\n\n    #testデータにも適応出来るように保存\n    dict_cat[col] = {}\n    dict_cat[col][\"fillna\"] = value_fillna\n    dict_cat[col][\"map_label\"] = map_label\n    dict_cat[col][\"num_label\"] = len(list_label)\n\nprint(\"Done.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:13:04.943858Z","iopub.execute_input":"2025-01-25T09:13:04.944203Z","iopub.status.idle":"2025-01-25T09:13:08.370108Z","shell.execute_reply.started":"2025-01-25T09:13:04.944159Z","shell.execute_reply":"2025-01-25T09:13:08.368950Z"}},"outputs":[{"name":"stdout","text":"playerId\ndayofweek\nbirthCity\nbirthStateProvince\nbirthCountry\nprimaryPositionCode\nprimaryPositionName\nteamId\nstatusCode\nstatus\nDone.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"#欠損値補間・正規化/数値化を関数化\ndef transform_data(input_x):\n    output_x = input_x.copy()\n\n    #数値データの欠損値補間・正規化\n    for col in col_num:\n        #欠損値補間：平均値で埋める\n        value_fillna = dict_num[col][\"fillna\"]\n        output_x[col] = output_x[col].fillna(value_fillna)\n    \n        #正規化（0~1になるように変換）\n        value_min = dict_num[col][\"min\"]\n        value_max = dict_num[col][\"max\"]\n        output_x[col] = (output_x[col] - value_min) / (value_max - value_min)\n\n    #カテゴリ変数の欠損値補間・数値化\n    for col in col_cat:\n        #欠損値補間：unknownで埋める\n        value_fillna = \"unknown\"\n        output_x[col] = output_x[col].fillna(value_fillna)\n    \n        #str型に変換\n        output_x[col] = output_x[col].astype(str)\n    \n        #ラベルエンコーダー：0から始まる整数に変換\n        map_label = dict_cat[col][\"map_label\"]\n        output_x[col] = output_x[col].map(map_label)\n        #対応するものがない場合はunknownラベルで埋める\n        output_x[col] = output_x[col].fillna(map_label[\"unknown\"])\n\n    return output_x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:13:08.371453Z","iopub.execute_input":"2025-01-25T09:13:08.371857Z","iopub.status.idle":"2025-01-25T09:13:08.379093Z","shell.execute_reply.started":"2025-01-25T09:13:08.371828Z","shell.execute_reply":"2025-01-25T09:13:08.377840Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"#ニューラルネットワークのモデル定義\ndef create_model(col_num = [\"heightInches\",\"weight\"],\n                col_cat = [\"playerId\",\"teamId\",\"dayofweek\"],\n                show=False,\n                ):\n    input_num = Input(shape=(len(col_num),))\n    input_cat = Input(shape=(len(col_cat),))\n\n    #numeric\n    x_num = input_num\n\n    #category\n    for i,col in enumerate(col_cat):\n        tmp_cat = input_cat[:,i]\n        input_dim = dict_cat[col][\"num_label\"]\n        output_dim = int(input_dim/2)\n        tmp_cat = Embedding(input_dim=input_dim, output_dim=output_dim)(tmp_cat)\n        tmp_cat = Dropout(0.2)(tmp_cat)\n        tmp_cat = Flatten()(tmp_cat)\n        if i==0:\n            x_cat = tmp_cat\n        else:\n            x_cat = Concatenate()([x_cat,tmp_cat])\n\n    #concat\n    x = Concatenate()([x_num,x_cat])\n    x = Dense(128, activation=\"relu\")(x)\n    x = Dropout(0.1)(x)\n    output = Dense(4, activation=\"linear\")(x)\n\n    model = Model(inputs=[input_num,input_cat],outputs=output)\n    model.compile(optimizer=\"Adam\",loss=\"mae\",metrics=[\"mae\"])\n\n    if show:\n        print(model.summary())\n    else:\n        return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:13:08.380596Z","iopub.execute_input":"2025-01-25T09:13:08.381026Z","iopub.status.idle":"2025-01-25T09:13:08.406033Z","shell.execute_reply.started":"2025-01-25T09:13:08.380997Z","shell.execute_reply":"2025-01-25T09:13:08.404649Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"#モデル構造の確認\ncreate_model(col_num=col_num,\n            col_cat=col_cat,\n            show=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:13:08.407253Z","iopub.execute_input":"2025-01-25T09:13:08.407541Z","iopub.status.idle":"2025-01-25T09:13:08.721626Z","shell.execute_reply.started":"2025-01-25T09:13:08.407517Z","shell.execute_reply":"2025-01-25T09:13:08.720425Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item (\u001b[38;5;33mGetItem\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_1 (\u001b[38;5;33mGetItem\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1031\u001b[0m)           │      \u001b[38;5;34m2,125,922\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m32\u001b[0m │ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_2 (\u001b[38;5;33mGetItem\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1031\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m514\u001b[0m)            │        \u001b[38;5;34m528,392\u001b[0m │ get_item_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_3 (\u001b[38;5;33mGetItem\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1031\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m514\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │          \u001b[38;5;34m2,628\u001b[0m │ get_item_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_4 (\u001b[38;5;33mGetItem\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1035\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n│                           │                        │                │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m514\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │            \u001b[38;5;34m406\u001b[0m │ get_item_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_5 (\u001b[38;5;33mGetItem\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1549\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │             \u001b[38;5;34m78\u001b[0m │ get_item_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_6 (\u001b[38;5;33mGetItem\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1585\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m55\u001b[0m │ get_item_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_7 (\u001b[38;5;33mGetItem\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1599\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ embedding_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │            \u001b[38;5;34m465\u001b[0m │ get_item_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_8 (\u001b[38;5;33mGetItem\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1605\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m55\u001b[0m │ get_item_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_9 (\u001b[38;5;33mGetItem\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1610\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ embedding_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m128\u001b[0m │ get_item_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1625\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ embedding_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1630\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1638\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_9             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1661\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ concatenate_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m212,736\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m516\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1031</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,125,922</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1031</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528,392</span> │ get_item_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1031</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,628</span> │ get_item_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1035</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n│                           │                        │                │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">406</span> │ get_item_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1549</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span> │ get_item_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1585</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │ get_item_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1599</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">465</span> │ get_item_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1605</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │ get_item_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1610</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ get_item_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1625</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1630</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1638</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_9             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1661</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">212,736</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,871,413\u001b[0m (10.95 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,871,413</span> (10.95 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,871,413\u001b[0m (10.95 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,871,413</span> (10.95 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"None\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"import tensorflow as tf\n#tensorflowの再現性のためのシード指定関数\ndef seed_everything(seed):\n    import random\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:13:08.723024Z","iopub.execute_input":"2025-01-25T09:13:08.723389Z","iopub.status.idle":"2025-01-25T09:13:08.729784Z","shell.execute_reply.started":"2025-01-25T09:13:08.723360Z","shell.execute_reply":"2025-01-25T09:13:08.728215Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"#学習用の関数をニューラルネットワーク用にカスタマイズ\ndef train_tf(input_x,\n              input_y,\n              input_id,\n              list_nfold=[0,1,2], \n              mode_train=\"train\",\n             batch_size=1024,\n             epochs=100,\n             ):\n    #推論値を格納する変数の作成\n    df_valid_pred = pd.DataFrame()\n    #評価値を入れる変数の作成\n    metrics = []\n\n    #validation\n    cv = []\n    for month_tr,month_va in list_cv_month:\n        cv.append([\n            input_id.index[input_id[\"yearmonth\"].isin(month_tr)],\n            input_id.index[input_id[\"yearmonth\"].isin(month_va) &\n            (input_id[\"playerForTestSetAndFuturePreds\"]==1)],\n        ])\n\n    #モデル学習(target/foldごとに学習)\n    for nfold in list_nfold:\n        print(\"-\"*20,\"fold:\", nfold,\"-\"*20)\n        #trainとvalidに分離\n        idx_tr,idx_va = cv[nfold][0],cv[nfold][1]\n    \n        x_num_tr,x_cat_tr,y_tr = input_x.loc[idx_tr,col_num].values,input_x.loc[\n        idx_tr,col_cat].values,input_y.loc[idx_tr,:].values\n        x_num_va,x_cat_va,y_va = input_x.loc[idx_va,col_num].values,input_x.loc[\n        idx_va,col_cat].values,input_y.loc[idx_va,:].values  \n        print(x_num_tr.shape,x_cat_tr.shape,y_tr.shape)\n        print(x_num_va.shape,x_cat_va.shape,y_va.shape)\n\n        #保存するモデルのファイル名\n        filepath = \"model_tf_fold{}.weights.h5\".format(nfold)\n\n        if mode_train == \"train\":\n            print(\"training start.\")\n            seed_everything(seed=123)\n            model = create_model(col_num=col_num,col_cat=col_cat,show=False)\n            model.fit(x=[x_num_tr,x_cat_tr],\n                     y=y_tr,\n                     validation_data=([x_num_va,x_cat_va],y_va),\n                      batch_size=batch_size,\n                      epochs=epochs,\n                     callbacks=[\n                    ModelCheckpoint(filepath= filepath,monitor=\"val_loss\",\n                                   mode=\"min\",verbose=1,save_weights_only=True),\n                    EarlyStopping(monitor=\"val_loss\",mode=\"min\",min_delta=0,\n                                 patience=10,verbose=1,restore_best_weights=True),\n                    ReduceLROnPlateau(monitor=\"val_loss\",mode=\"min\",factor=0.1,patience=5,verbose=1),\n                     ],\n                      verbose=1,\n                     )\n        else:\n            print(\"model load.\")\n            model = create_model(col_num=col_num,col_cat=col_cat,show=False)\n            model.load_weights(filepath)\n            print(\"Done.\")\n            \n        #validの推論値取得\n        y_va_pred = model.predict([x_num_va,x_cat_va])\n        tmp_pred = pd.concat([\n            id_va,\n            pd.DataFrame(y_va,columns=[\"target1_true\",\"target2_true\",\"target3_true\",\"target4_true\"]),\n            pd.DataFrame(y_va_pred,columns=[\"target1_pred\",\"target2_pred\",\"target3_pred\",\"target4_pred\"]),\n        ],axis=1)\n        tmp_pred[\"nfold\"] = nfold\n        df_valid_pred = pd.concat([df_valid_pred,tmp_pred],axis=0,ignore_index=True)\n\n        #評価値の算出\n        metrics.append([\"target1\",nfold,np.mean(np.abs(y_va[:,0] - y_va_pred[:,0]))])\n        metrics.append([\"target2\",nfold,np.mean(np.abs(y_va[:,1] - y_va_pred[:,1]))])\n        metrics.append([\"target3\",nfold,np.mean(np.abs(y_va[:,2] - y_va_pred[:,2]))])\n        metrics.append([\"target4\",nfold,np.mean(np.abs(y_va[:,3] - y_va_pred[:,3]))])\n                                               \n    print(\"-\"*10,\"result\",\"-\"*10)\n    #評価値\n    df_metrics = pd.DataFrame(metrics,columns=[\"target\",\"nfold\",\"mae\"])\n    print(\"MCMAE: {:.4f}\".format(df_metrics[\"mae\"].mean()))\n\n    #validの推論値\n    df_valid_pred_all = pd.pivot_table(df_valid_pred,index=\n                               [\"engagementMetricsDate\",\"playerId\",\"date_playerId\",\n                                \"date\",\"yearmonth\",\"playerForTestSetAndFuturePreds\"],columns=[\"nfold\"],\n                                       values=list(df_valid_pred.columns[df_valid_pred.columns.str.contains(\"target\")]),aggfunc=np.sum)\n    df_valid_pred_all.columns = [\"{}_fold{}_{}\".format(i.split(\"_\")[0],j,i.split(\"_\")[1]) for i,j in df_valid_pred_all.columns]\n    df_valid_pred_all = df_valid_pred_all.reset_index(drop=False)\n\n    return df_valid_pred_all, df_metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:13:08.731249Z","iopub.execute_input":"2025-01-25T09:13:08.731669Z","iopub.status.idle":"2025-01-25T09:13:08.753646Z","shell.execute_reply.started":"2025-01-25T09:13:08.731619Z","shell.execute_reply":"2025-01-25T09:13:08.752270Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"#学習の実行\ndf_valid_pred,df_metrics = train_tf(x_train,\n                                   y_train,\n                                   id_train,\n                                   list_nfold=[0,1,2],\n                                   mode_train=\"train\",\n                                   batch_size=1024,\n                                   epochs=1000,\n                                   )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:13:08.754910Z","iopub.execute_input":"2025-01-25T09:13:08.755281Z","iopub.status.idle":"2025-01-25T09:57:49.805411Z","shell.execute_reply.started":"2025-01-25T09:13:08.755245Z","shell.execute_reply":"2025-01-25T09:57:49.803912Z"}},"outputs":[{"name":"stdout","text":"-------------------- fold: 0 --------------------\n(752265, 23) (752265, 10) (752265, 4)\n(36797, 23) (36797, 10) (36797, 4)\ntraining start.\nEpoch 1/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.9538 - mae: 0.9538\nEpoch 1: saving model to model_tf_fold0.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 63ms/step - loss: 0.9537 - mae: 0.9537 - val_loss: 1.3965 - val_mae: 1.3965 - learning_rate: 0.0010\nEpoch 2/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8807 - mae: 0.8807\nEpoch 2: saving model to model_tf_fold0.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 62ms/step - loss: 0.8807 - mae: 0.8807 - val_loss: 1.3952 - val_mae: 1.3952 - learning_rate: 0.0010\nEpoch 3/1000\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8689 - mae: 0.8689\nEpoch 3: saving model to model_tf_fold0.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 62ms/step - loss: 0.8689 - mae: 0.8689 - val_loss: 1.3950 - val_mae: 1.3950 - learning_rate: 0.0010\nEpoch 4/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8627 - mae: 0.8627\nEpoch 4: saving model to model_tf_fold0.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 61ms/step - loss: 0.8627 - mae: 0.8627 - val_loss: 1.3977 - val_mae: 1.3977 - learning_rate: 0.0010\nEpoch 5/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8590 - mae: 0.8590\nEpoch 5: saving model to model_tf_fold0.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 63ms/step - loss: 0.8590 - mae: 0.8590 - val_loss: 1.3997 - val_mae: 1.3997 - learning_rate: 0.0010\nEpoch 6/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8559 - mae: 0.8559\nEpoch 6: saving model to model_tf_fold0.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 64ms/step - loss: 0.8559 - mae: 0.8559 - val_loss: 1.3984 - val_mae: 1.3984 - learning_rate: 0.0010\nEpoch 7/1000\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.8536 - mae: 0.8536\nEpoch 7: saving model to model_tf_fold0.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - loss: 0.8536 - mae: 0.8536 - val_loss: 1.4001 - val_mae: 1.4001 - learning_rate: 0.0010\nEpoch 8/1000\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.8516 - mae: 0.8516\nEpoch 8: saving model to model_tf_fold0.weights.h5\n\nEpoch 8: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 74ms/step - loss: 0.8516 - mae: 0.8516 - val_loss: 1.4019 - val_mae: 1.4019 - learning_rate: 0.0010\nEpoch 9/1000\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.8485 - mae: 0.8485\nEpoch 9: saving model to model_tf_fold0.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 71ms/step - loss: 0.8485 - mae: 0.8485 - val_loss: 1.3983 - val_mae: 1.3983 - learning_rate: 1.0000e-04\nEpoch 10/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.8442 - mae: 0.8442\nEpoch 10: saving model to model_tf_fold0.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 68ms/step - loss: 0.8442 - mae: 0.8442 - val_loss: 1.3983 - val_mae: 1.3983 - learning_rate: 1.0000e-04\nEpoch 11/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8428 - mae: 0.8428\nEpoch 11: saving model to model_tf_fold0.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 64ms/step - loss: 0.8427 - mae: 0.8427 - val_loss: 1.3991 - val_mae: 1.3991 - learning_rate: 1.0000e-04\nEpoch 12/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8422 - mae: 0.8422\nEpoch 12: saving model to model_tf_fold0.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 64ms/step - loss: 0.8422 - mae: 0.8422 - val_loss: 1.3993 - val_mae: 1.3993 - learning_rate: 1.0000e-04\nEpoch 13/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8415 - mae: 0.8415\nEpoch 13: saving model to model_tf_fold0.weights.h5\n\nEpoch 13: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 62ms/step - loss: 0.8415 - mae: 0.8415 - val_loss: 1.3999 - val_mae: 1.3999 - learning_rate: 1.0000e-04\nEpoch 13: early stopping\nRestoring model weights from the end of the best epoch: 3.\n\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n-------------------- fold: 1 --------------------\n(752265, 23) (752265, 10) (752265, 4)\n(35610, 23) (35610, 10) (35610, 4)\ntraining start.\nEpoch 1/1000\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.9317 - mae: 0.9317\nEpoch 1: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 63ms/step - loss: 0.9317 - mae: 0.9317 - val_loss: 1.3733 - val_mae: 1.3733 - learning_rate: 0.0010\nEpoch 2/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8788 - mae: 0.8788\nEpoch 2: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 62ms/step - loss: 0.8788 - mae: 0.8788 - val_loss: 1.3684 - val_mae: 1.3684 - learning_rate: 0.0010\nEpoch 3/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8696 - mae: 0.8696\nEpoch 3: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 62ms/step - loss: 0.8696 - mae: 0.8696 - val_loss: 1.3639 - val_mae: 1.3639 - learning_rate: 0.0010\nEpoch 4/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8643 - mae: 0.8643\nEpoch 4: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 62ms/step - loss: 0.8643 - mae: 0.8643 - val_loss: 1.3607 - val_mae: 1.3607 - learning_rate: 0.0010\nEpoch 5/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8603 - mae: 0.8603\nEpoch 5: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 62ms/step - loss: 0.8603 - mae: 0.8603 - val_loss: 1.3589 - val_mae: 1.3589 - learning_rate: 0.0010\nEpoch 6/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8576 - mae: 0.8576\nEpoch 6: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 61ms/step - loss: 0.8576 - mae: 0.8576 - val_loss: 1.3582 - val_mae: 1.3582 - learning_rate: 0.0010\nEpoch 7/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8554 - mae: 0.8554\nEpoch 7: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 61ms/step - loss: 0.8554 - mae: 0.8554 - val_loss: 1.3577 - val_mae: 1.3577 - learning_rate: 0.0010\nEpoch 8/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8533 - mae: 0.8533\nEpoch 8: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 61ms/step - loss: 0.8533 - mae: 0.8533 - val_loss: 1.3587 - val_mae: 1.3587 - learning_rate: 0.0010\nEpoch 9/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8517 - mae: 0.8517\nEpoch 9: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 62ms/step - loss: 0.8517 - mae: 0.8517 - val_loss: 1.3578 - val_mae: 1.3578 - learning_rate: 0.0010\nEpoch 10/1000\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.8501 - mae: 0.8501\nEpoch 10: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 69ms/step - loss: 0.8501 - mae: 0.8501 - val_loss: 1.3571 - val_mae: 1.3571 - learning_rate: 0.0010\nEpoch 11/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.8495 - mae: 0.8495\nEpoch 11: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 68ms/step - loss: 0.8495 - mae: 0.8495 - val_loss: 1.3610 - val_mae: 1.3610 - learning_rate: 0.0010\nEpoch 12/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.8482 - mae: 0.8482\nEpoch 12: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 67ms/step - loss: 0.8482 - mae: 0.8482 - val_loss: 1.3594 - val_mae: 1.3594 - learning_rate: 0.0010\nEpoch 13/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8473 - mae: 0.8473\nEpoch 13: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 63ms/step - loss: 0.8473 - mae: 0.8473 - val_loss: 1.3614 - val_mae: 1.3614 - learning_rate: 0.0010\nEpoch 14/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8463 - mae: 0.8463\nEpoch 14: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 63ms/step - loss: 0.8463 - mae: 0.8463 - val_loss: 1.3581 - val_mae: 1.3581 - learning_rate: 0.0010\nEpoch 15/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8454 - mae: 0.8454\nEpoch 15: saving model to model_tf_fold1.weights.h5\n\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 61ms/step - loss: 0.8454 - mae: 0.8454 - val_loss: 1.3614 - val_mae: 1.3614 - learning_rate: 0.0010\nEpoch 16/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8425 - mae: 0.8425\nEpoch 16: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 61ms/step - loss: 0.8425 - mae: 0.8425 - val_loss: 1.3606 - val_mae: 1.3606 - learning_rate: 1.0000e-04\nEpoch 17/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8391 - mae: 0.8391\nEpoch 17: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 62ms/step - loss: 0.8391 - mae: 0.8391 - val_loss: 1.3612 - val_mae: 1.3612 - learning_rate: 1.0000e-04\nEpoch 18/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8378 - mae: 0.8378\nEpoch 18: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 61ms/step - loss: 0.8378 - mae: 0.8378 - val_loss: 1.3614 - val_mae: 1.3614 - learning_rate: 1.0000e-04\nEpoch 19/1000\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8376 - mae: 0.8376\nEpoch 19: saving model to model_tf_fold1.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 61ms/step - loss: 0.8376 - mae: 0.8376 - val_loss: 1.3618 - val_mae: 1.3618 - learning_rate: 1.0000e-04\nEpoch 20/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8367 - mae: 0.8367\nEpoch 20: saving model to model_tf_fold1.weights.h5\n\nEpoch 20: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 62ms/step - loss: 0.8367 - mae: 0.8367 - val_loss: 1.3623 - val_mae: 1.3623 - learning_rate: 1.0000e-04\nEpoch 20: early stopping\nRestoring model weights from the end of the best epoch: 10.\n\u001b[1m1113/1113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n-------------------- fold: 2 --------------------\n(752265, 23) (752265, 10) (752265, 4)\n(36797, 23) (36797, 10) (36797, 4)\ntraining start.\nEpoch 1/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9248 - mae: 0.9248\nEpoch 1: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 62ms/step - loss: 0.9247 - mae: 0.9247 - val_loss: 1.0935 - val_mae: 1.0935 - learning_rate: 0.0010\nEpoch 2/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8766 - mae: 0.8766\nEpoch 2: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 61ms/step - loss: 0.8766 - mae: 0.8766 - val_loss: 1.0895 - val_mae: 1.0895 - learning_rate: 0.0010\nEpoch 3/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8701 - mae: 0.8701\nEpoch 3: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 61ms/step - loss: 0.8701 - mae: 0.8701 - val_loss: 1.0901 - val_mae: 1.0901 - learning_rate: 0.0010\nEpoch 4/1000\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.8663 - mae: 0.8663\nEpoch 4: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 67ms/step - loss: 0.8663 - mae: 0.8663 - val_loss: 1.0890 - val_mae: 1.0890 - learning_rate: 0.0010\nEpoch 5/1000\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.8631 - mae: 0.8631\nEpoch 5: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 76ms/step - loss: 0.8631 - mae: 0.8631 - val_loss: 1.0905 - val_mae: 1.0905 - learning_rate: 0.0010\nEpoch 6/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.8605 - mae: 0.8605\nEpoch 6: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 71ms/step - loss: 0.8605 - mae: 0.8605 - val_loss: 1.0895 - val_mae: 1.0895 - learning_rate: 0.0010\nEpoch 7/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8583 - mae: 0.8583\nEpoch 7: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 63ms/step - loss: 0.8583 - mae: 0.8583 - val_loss: 1.0912 - val_mae: 1.0912 - learning_rate: 0.0010\nEpoch 8/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8562 - mae: 0.8562\nEpoch 8: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 63ms/step - loss: 0.8562 - mae: 0.8562 - val_loss: 1.0937 - val_mae: 1.0937 - learning_rate: 0.0010\nEpoch 9/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8546 - mae: 0.8546\nEpoch 9: saving model to model_tf_fold2.weights.h5\n\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 63ms/step - loss: 0.8546 - mae: 0.8546 - val_loss: 1.0928 - val_mae: 1.0928 - learning_rate: 0.0010\nEpoch 10/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8514 - mae: 0.8514\nEpoch 10: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 63ms/step - loss: 0.8514 - mae: 0.8514 - val_loss: 1.0895 - val_mae: 1.0895 - learning_rate: 1.0000e-04\nEpoch 11/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8484 - mae: 0.8484\nEpoch 11: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 63ms/step - loss: 0.8484 - mae: 0.8484 - val_loss: 1.0894 - val_mae: 1.0894 - learning_rate: 1.0000e-04\nEpoch 12/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8474 - mae: 0.8474\nEpoch 12: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 62ms/step - loss: 0.8474 - mae: 0.8474 - val_loss: 1.0886 - val_mae: 1.0886 - learning_rate: 1.0000e-04\nEpoch 13/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8465 - mae: 0.8465\nEpoch 13: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 62ms/step - loss: 0.8465 - mae: 0.8465 - val_loss: 1.0899 - val_mae: 1.0899 - learning_rate: 1.0000e-04\nEpoch 14/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8462 - mae: 0.8462\nEpoch 14: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 62ms/step - loss: 0.8462 - mae: 0.8462 - val_loss: 1.0900 - val_mae: 1.0900 - learning_rate: 1.0000e-04\nEpoch 15/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8458 - mae: 0.8458\nEpoch 15: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 62ms/step - loss: 0.8458 - mae: 0.8458 - val_loss: 1.0906 - val_mae: 1.0906 - learning_rate: 1.0000e-04\nEpoch 16/1000\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8452 - mae: 0.8452\nEpoch 16: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 63ms/step - loss: 0.8452 - mae: 0.8452 - val_loss: 1.0916 - val_mae: 1.0916 - learning_rate: 1.0000e-04\nEpoch 17/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8447 - mae: 0.8447\nEpoch 17: saving model to model_tf_fold2.weights.h5\n\nEpoch 17: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 63ms/step - loss: 0.8447 - mae: 0.8447 - val_loss: 1.0907 - val_mae: 1.0907 - learning_rate: 1.0000e-04\nEpoch 18/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.8446 - mae: 0.8446\nEpoch 18: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 66ms/step - loss: 0.8446 - mae: 0.8446 - val_loss: 1.0926 - val_mae: 1.0926 - learning_rate: 1.0000e-05\nEpoch 19/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.8442 - mae: 0.8442\nEpoch 19: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - loss: 0.8442 - mae: 0.8442 - val_loss: 1.0927 - val_mae: 1.0927 - learning_rate: 1.0000e-05\nEpoch 20/1000\n\u001b[1m734/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.8438 - mae: 0.8438\nEpoch 20: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 65ms/step - loss: 0.8438 - mae: 0.8438 - val_loss: 1.0927 - val_mae: 1.0927 - learning_rate: 1.0000e-05\nEpoch 21/1000\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.8441 - mae: 0.8441\nEpoch 21: saving model to model_tf_fold2.weights.h5\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 66ms/step - loss: 0.8441 - mae: 0.8441 - val_loss: 1.0927 - val_mae: 1.0927 - learning_rate: 1.0000e-05\nEpoch 22/1000\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.8436 - mae: 0.8436\nEpoch 22: saving model to model_tf_fold2.weights.h5\n\nEpoch 22: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 69ms/step - loss: 0.8436 - mae: 0.8436 - val_loss: 1.0929 - val_mae: 1.0929 - learning_rate: 1.0000e-05\nEpoch 22: early stopping\nRestoring model weights from the end of the best epoch: 12.\n\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n---------- result ----------\nMCMAE: 1.2803\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"print(\"MCMAE:{:.4f}\".format(df_metrics[\"mae\"].mean()))\ndisplay(pd.pivot_table(df_metrics,index=\"nfold\",columns=\"target\",values=\"mae\",aggfunc=np.mean,margins=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T09:57:49.806864Z","iopub.execute_input":"2025-01-25T09:57:49.807247Z","iopub.status.idle":"2025-01-25T09:57:49.849083Z","shell.execute_reply.started":"2025-01-25T09:57:49.807207Z","shell.execute_reply":"2025-01-25T09:57:49.847902Z"}},"outputs":[{"name":"stdout","text":"MCMAE:1.2803\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"target    target1    target2    target3    target4        All\nnfold                                                        \n0          1.2824     2.2135     0.8781     1.2061     1.3950\n1          1.1698     1.9171     0.8283     1.5133     1.3571\n2          1.0887     1.6083     0.7500     0.9076     1.0886\nAll        1.1803     1.9129     0.8188     1.2090     1.2803","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>target</th>\n      <th>target1</th>\n      <th>target2</th>\n      <th>target3</th>\n      <th>target4</th>\n      <th>All</th>\n    </tr>\n    <tr>\n      <th>nfold</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.2824</td>\n      <td>2.2135</td>\n      <td>0.8781</td>\n      <td>1.2061</td>\n      <td>1.3950</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.1698</td>\n      <td>1.9171</td>\n      <td>0.8283</td>\n      <td>1.5133</td>\n      <td>1.3571</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0887</td>\n      <td>1.6083</td>\n      <td>0.7500</td>\n      <td>0.9076</td>\n      <td>1.0886</td>\n    </tr>\n    <tr>\n      <th>All</th>\n      <td>1.1803</td>\n      <td>1.9129</td>\n      <td>0.8188</td>\n      <td>1.2090</td>\n      <td>1.2803</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":46}]}